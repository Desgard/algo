'use strict';(function(){const indexCfg={cache:true};indexCfg.doc={id:'id',field:['title','content'],store:['title','href','section'],};const index=FlexSearch.create('balance',indexCfg);window.bookSearchIndex=index;index.add({'id':3,'href':'/algo/docs/part4/ch03/4-edmond-karp/','title':"Edmond-Karp 最大流算法详解",'section':"Docs",'content':"知识梳理 #   在「初识最大流问题」中，我们了解了什么是流网络模型、什么是最大流问题、以及在流网络中 的增广路（Augmenting Path）概念； 在「Ford-Fulkerson 最大流求解方法」中，我们学习了 Ford-Fulkerson 的最大流问题求解方法和思路：不断的深度优先搜索，直到没有增广路为止则获得最大流； 在「二分匹配的最大流思维」中，通过增加超级源和超级汇来修改二分图，从而将二分匹配问题转换成了最大流问题，最后通过 Ford-Fulkerson 方法解决。  以上三篇先导文章都是在认识和使用最大流这种问题模型，从而进行一些算法思考。但是我们始终没有关心 Ford-Fulkerson 方法的时间复杂度问题。\n这篇文章会讲述一个求解最大流问题的 EK 算法，从而优化在某些场景下最大流问题的求解效率。\nFord-Fulkerson 方法有什么问题？ #  我们知道，在之前讨论的图中，根据 Ford-Fulkerson 方法，我们采用深度优先搜索（下文简称 DFS），不断的去寻找查询增广路，从而增加超级汇点的流量。先来复习一下 Ford-Fulkerson 方法的算法流程：\n 使用 DFS 搜索 出一条增广路； 在这条路径中所有的边的容量减去这条增广路的流量 f，并建立容量为 f 的反向边； 返回操作一，直到没有增广路；  在这个算法流程中，为将 “使用 DFS” 进行了加粗，你一定察觉到一些端倪。我们来从这个角度来思考一下：\n假设有一个网络流如上图所示，我们可以一眼看出最大流是 99。但是在我们代码中使用 Fold-Fulkerson 算法进行查找增广路的过程中，由于根据标号进行搜索，所以一定会先找到 S → A → C → \u0026hellip;. → D → E → T 这条增广路。于是我们就浪费了很多开销。\n其实我们在这个问题中，只要找到 S → B → E → T 这条增广路，就可以将 T 的入度达到满流状态，后续也就直接结束了。\n算法导论上给出的最坏情况分析 #  如果有一个图，某一条边是一个“噪声边”（所谓“噪声”就是指它在最终的结果中是没有对汇点进行增广的，也就是没有贡献流量的），**它的容量很少，并且它在 DFS 搜索中，位置十分靠前，每一次都优先搜到了这一条增广路，那么在每一个二次搜索增广路的时候，都会去抵消它的流量，通过反向边完成一次真实的增广操作。**这样问题就十分严重了。我举一个例子：\n上面这个图，我们看一眼就知道它的结果是 s → 0 → t 和 s → 1 → t 这两个增广路贡献的流量和 199，但是由于 0 → 1 这条边的序号十分靠前，所以每次在进行搜索增广路的过程中，就会优先使用 S → A → B → T 这条边；然后在第二次选择增广路时，我们选择了 S → B → A → T ，如此这样反复，我们发现每一次找到增广路，只增加了 1 个单位的流量，所以如此反复 199 次才能完成最大流算法的计算。\n我们用动图来描述一下这个场景：\n您的浏览器不支持 video 标签。  结合代码，我们来看看到底进行了多少次的增广操作：\n#include \u0026lt;iostream\u0026gt;#include \u0026lt;vector\u0026gt;#include \u0026lt;queue\u0026gt;#include \u0026lt;unordered_map\u0026gt;using namespace std; #define INF 0x3f3f3f3f  const int MAX_V = 1e4 + 5; struct Edge { int to, cap, rev; Edge(int _to, int _cap, int _rev): to(_to), cap(_cap), rev(_rev) {} }; // 邻接表记录点和其相连的边 // 比如节点 1 的所有出度边集 G[1] vector\u0026lt;Edge\u0026gt; G[MAX_V]; void add_edge(int from, int to, int cap) { G[from].push_back(Edge(to, cap, G[to].size())); G[to].push_back(Edge(from, 0, G[from].size() - 1)); } bool used[MAX_V]; int dfs(int c, int t, int f) { if (c == t) { return f; } used[c] = true; for (int i = 0; i \u0026lt; G[c].size(); ++ i) { Edge \u0026amp;e = G[c][i]; if (!used[e.to] \u0026amp;\u0026amp; e.cap \u0026gt; 0) { int d = dfs(e.to, t, min(f, e.cap)); if (d \u0026gt; 0) { e.cap -= d; G[e.to][e.rev].cap += d; return d; } } } return 0; } int max_flow(int s, int t) { int flow = 0; int cnt = 0; for (;;) { memset(used, 0, sizeof(used)); int f = dfs(s, t, INF); cnt += 1; if (f == 0) { cout \u0026lt;\u0026lt; cnt \u0026lt;\u0026lt; endl; // 5 - 也就是说只进行了 5 次增广路查询  return flow; } flow += f; } } int main() { // 0: S点  // 1: A点  // 2: B点  // 3: T点  add_edge(0, 1, 99); add_edge(0, 2, 100); add_edge(1, 2, 1); add_edge(1, 3, 100); add_edge(2, 3, 100); int ret = max_flow(0, 3); cout \u0026lt;\u0026lt; ret \u0026lt;\u0026lt; endl; // 199 } 但我们发现，即使先搜索了 S → A → B → T 这条增广路，也不会出现这种最坏情况。原因是因为我们所实现的 Ford-Fulkerson 方法是使用 DFS 深度优先搜索查找增广路，在实现中有这句：\nint d = dfs(e.to, t, min(f, e.cap)); 这个 DFS 中会有回溯流程，也就是说，当我们找到 S → A → B → T 之后，对所有边的容量减 1 ，此时回溯到了 A 点，则又会继续查找 S → A → T 这条增广路。所以我们并不能看到《算法导论》中讨论的这种最差情况。\n虽然这种极限情况是无法得到的，但是我们也知道了传统的 Ford-Fulkerson 方法还是存在优化的可能。\n基于 DFS 的 FF 方法复杂度分析 #  从上面这里例子，你已经发现了，当基于 DFS 的 FF 算法的最差情况复杂度是和最大流相关的。假设我们有 E 条边并且最大流是 F，每次 DFS 查增广路则需要 O(E) 的复杂度，当最大流是 E 的时候，我们要进行最多 E 次的增广路查找。\n所以基于 DFS 的 FF 算法的时间复杂度是：\n$$O(V·F)$$\n但是由于我们使用的是带有回溯的 DFS ，所以复杂度是要小于上述这个结果的。这个结果就是 Ford-Fulkerson 方法的算法复杂度上届。\nEdmond-Karp 算法解析 #  再回头看这个图，我们能得到什么启发呢？\n启发就是，如果我们能够尽早的找到 S → B → E → T 这条增广路是不是就可以了？\n沿着这个思路我们继续思考，是不是有一种搜索方式可以均衡分配到每一个搜索结果中相同的层级呢？是的，就是 BFS 广度优先搜索。是的，计算机科学家 Edmond-Karp 也是这么考虑的。\n我们再用《算法导论》中的流网络，配合 BFS 广度优先搜索，进行增广路的查找来看一下在 Edmond-Karp 最大流的代码实现中我们需要记录哪些信息？\n您的浏览器不支持 video 标签。  在 Edmond-Karp 最大流算法中，可以看到总流程也是分成 3 步：\n 使用 BFS 找到一条增广路（对应下面的步骤 1）； 计算这条路的最小容量边，为汇点加流量，并建立反向边，其容量为增加的流量（对应下面的步骤 2）； 重复第一步，如果不能找到一条增广路则得到最大流；  但是在实现上，由于我们采用了 BFS 方法，则无法对这条增广路进行回溯处理。所以在代码实现的时候，我们需要通过一个数组或者一个 Map 来记录下对应点在增广路上的入度边。\n下面我们来拆解这几步的实现单独来看。\n1. BFS 搜索查询增广路 #  为了解释 BFS 的查询方式，我又画了一个不规则的流网络来简书 BFS 查询最短路的流程：\n从这个过程中可以看出，我们从源点 S 进行 BFS 广度优先搜索，当第一次到达汇点 T 后就停止搜索，然后来执行我们的增加流量和建立反向边的操作。由于我们需要在到达汇点 T 后来处理这条路径，所以需要一个数组或者 Map 记录每一个节点的入度边，这样也就可以从后向前获取到这条路径了。\n// 用来记录当前路径上的最小容量，用于加流量操作 int a[MAX_V]; // 记录下标点的边编号，pair 对应 G[x1][x2]，x1 是描述哪个入度点，x2 是描述 x1 点的第 x2 条边 unordered_map\u0026lt;int, pair\u0026lt;int, int\u0026gt;\u0026gt; pre; 我们确定了要记录哪些信息，剩下的就是 BFS 流程了：\nvoid bfs(int s, int t) { // a 初始化成 0，也可以判断是否已经被染色，从而剪枝情况  memset(a, 0, sizeof(a)); // 使用队列，保存处理节点  queue\u0026lt;int\u0026gt; que; que.push(s); // 每个节点所流过的流量设置为 INF 无穷大 \t// 这样可以起到求最小的作用  a[s] = INF; while (!que.empty()) { int x = que.front(); que.pop(); // 遍历当前节点的所有边  for (int i = 0; i \u0026lt; G[x].size(); ++ i) { Edge\u0026amp; e = G[x][i]; // 如果相连的点没有访问，并且这条边的容量大于 0  if (!a[e.to] \u0026amp;\u0026amp; e.cap \u0026gt; 0) { // 记录下一个点的入度边  pre[e.to] = make_pair(x, i); // 计算当前路径的最小容量  a[e.to] = min(a[x], e.cap); que.push(e.to); } } if (a[t]) break; } } 2. 增广路径上的边与反向边的容量操作 #  在这个过程中，通过我们上方记录的 unordered_map\u0026lt;int, pair\u0026lt;int, int\u0026gt;\u0026gt; pre 前驱入度集合，从 T 点开始向前回溯，每次回溯的时候通过访问 int a[MAX_V] 来获得这条增广路上的最小流量，然后更新每一个边和反向边。\nint max_flow(int s, int t) { // 最大流结果  int ret = 0; while (1) { // 从 S -\u0026gt; T 使用 bfs 查询一条增广路  bfs(s, t); // 如果发现容量最小是 0 ，说明查不到了  if (a[t] == 0) break; int u = t; while (u != s) { // 使用 pre 来获取当前增广路中汇点 T 的入度边下标信息  int p = pre[u].first, edge_index = pre[u].second; // 获取正向边和反向边  Edge\u0026amp; forward_edge = G[p][edge_index]; Edge\u0026amp; reverse_edge = G[forward_edge.to][forward_edge.rev]; // 更新流量  forward_edge.cap -= a[t]; reverse_edge.cap += a[t]; // 逆增广路方向移动游标继续更新  u = reverse_edge.to; } ret += a[t]; } return ret; } EK 最大流完整实现 #  我们用 「Ford-Fulkerson 最大流方法」中的引例再做一次测试，这次使用 EK 算法来求解最大流。\n#include \u0026lt;iostream\u0026gt;#include \u0026lt;vector\u0026gt;#include \u0026lt;queue\u0026gt;#include \u0026lt;unordered_map\u0026gt;using namespace std; #define INF 0x3f3f3f3f  const int MAX_V = 1e4 + 5; struct Edge { int to, cap, rev; Edge(int _to, int _cap, int _rev): to(_to), cap(_cap), rev(_rev) {} }; vector\u0026lt;Edge\u0026gt; G[MAX_V]; int a[MAX_V]; unordered_map\u0026lt;int, pair\u0026lt;int, int\u0026gt;\u0026gt; pre; void add_edge(int from, int to, int cap) { G[from].push_back(Edge(to, cap, G[to].size())); G[to].push_back(Edge(from, 0, G[from].size() - 1)); } void bfs(int s, int t) { memset(a, 0, sizeof(a)); queue\u0026lt;int\u0026gt; que; que.push(s); a[s] = INF; while (!que.empty()) { int x = que.front(); que.pop(); for (int i = 0; i \u0026lt; G[x].size(); ++ i) { Edge\u0026amp; e = G[x][i]; if (!a[e.to] \u0026amp;\u0026amp; e.cap \u0026gt; 0) { pre[e.to] = make_pair(x, i); a[e.to] = min(a[x], e.cap); que.push(e.to); } } if (a[t]) break; } } int max_flow(int s, int t) { int ret = 0; while (1) { bfs(s, t); if (a[t] == 0) break; int u = t; while (u != s) { int p = pre[u].first, edge_index = pre[u].second; Edge\u0026amp; forward_edge = G[p][edge_index]; Edge\u0026amp; reverse_edge = G[forward_edge.to][forward_edge.rev]; forward_edge.cap -= a[t]; reverse_edge.cap += a[t]; u = reverse_edge.to; } ret += a[t]; } return ret; } int main() { add_edge(0, 1, 16); add_edge(0, 3, 13); add_edge(1, 2, 12); add_edge(2, 3, 9); add_edge(2, 5, 20); add_edge(3, 1, 4); add_edge(3, 4, 14); add_edge(4, 2, 7); add_edge(4, 5, 4); int ret = max_flow(0, 5); // 输出 23  cout \u0026lt;\u0026lt; ret \u0026lt;\u0026lt; endl; } 发现同样的，最终结果输出 23 是最大流，符合我们预期结果。\nEK 算法时间复杂度及适用情况 #  由于这次我们使用了 BFS 求解增广路，假设我们的节点数量是 V，边的数量是 E，则 EK 算法的时间复杂度上限是：\n  \\[O(V·E^2)\\]  分析起来很简单，因为 BFS 找增广路的时间复杂度是 O(E)，最多需要 O(V·E) 次查询，所以可得到答案。如果想看证明，我会在「阅读原文」中的「一瓜算法小册」中进行更新。\n我们已经知道了 FF 算法和 EK 算法的复杂度：\n \\[T_{FF} = O(E·F)\\]   \\[T_{EK}=O(V·E^2)\\]  根据复杂度，我们可以总结出这么一个结论（E 是边的数量，V 是节点数量）：\n 当流网络中边少的时候，或者说是一个**稀疏图（E \u0026lt; VlogV）**时，我们可以选用 EK 算法进行最大流求解； 当流网络中边多的时候，或者说是一个**稠密图（E \u0026gt; VlogV）**时，可以选用 FF 方法求解。  总结 #  对于最大流算法优化的讨论，我们已经完成了第一步 —— 学习 EK 算法。EK 算法启发我们可以通过 BFS 对增广路进行查询，从而消除 DFS 中查找增广路的时间不确定性，让效率在不同的流网络中可控。\n在 Fold-Fulkerson 方法的基础之上，我们了解了增广路，了解了最小割。但是对于流量而言，无论是 FF 方法还是 EK 算法，我们一直都忽视了一个重要的关键，那就是对距离的描述。下一篇文章我们来讲述在距离的帮助下，什么是分层网络，以及 Dinic 最大流算法是如何优化的！\n"});index.add({'id':4,'href':'/algo/docs/part4/ch03/2-ford-fulkerson/','title':"Ford-Fulkerson 最大流求解方法",'section':"Docs",'content':"在上一节《初识最大流问题》中，已经讲到了网络流中的一个经典问题 - 最大流问题。同上一篇的方式一样，这篇文章你要带着以下两个问题来阅读：\n 怎样搜索到一条增广路？ 如何利用搜索到的增广路求解最大流问题？ Ford-Fulkerson 算法求最大流的原理是什么？  如何求得最大流 #  我们继续引用上文的例子：\n 假设有这么一个例子，这次 2019-nCoV 疫情让口罩变成了稀缺资源。所以，全国各地都在为武汉捐献物资。假设现在因为种种原因，我们只能通过地面线路来运输口罩物资，并且每一条线路是有流量限制的。假设不考虑运输速度，并且源点 S （杭州）的口罩物资产量是足够多的，我们需要求解汇点 T（武汉）在不计速度的情况下能收到多少物资？\n 首先我们拍脑袋来自己探索一个算法，计算最大流。\n我们的目标是找到增广路，所以我们制定一个策略：通过 DFS 深度优先搜索，来检索一条增光路，然后计算从 S 到 T 的最大流量，并在所有的边流量容量中将其扣除。反复按照这种操作，来迭代我们每次扣除之后的残余网络，最后无法再找到增广路则停止搜索，求得我们的“最大流”。\n我们来做一个动图来描述一下这个过程：\n您的浏览器不支持 video 标签。  这个动图中描述的算法包括以下三步：\n 搜索出一条增广路； 在这条路径中所有的边容量减去这条增广路的流量，如果容量为 0 则拆边； 返回操作一，如果没有增广路则得到答案。  在这道例题中，我负责任的告诉你，答案确实是最大流 23。但是求解的过程是错的！ 为什么会造成过程是错的，但是答案是对的的情况？原因是因为这个流网络的最大流刚好是我们这种做法所得到的答案。那正确的解法应该是怎样的？我们在来看一个图：\n我们按照上文的方法来求解一下最大流。\n我们通过上述的三步流程进行演算，最终获得的残余网络如上，求得最大流是 10。\n但是我在这里再次负责的告诉你，**这个结果是不正确的！**理由如下：\n按照这种方式来处理流量，可以获得最大流 11 的答案，这是更优的结果。由此我们证明了上述我们自己构造的算法是有问题的。可是问题出在哪呢？我们对比一下两张图的流量差：\n通过对比流量差，我们 发现其中 1 → 2 会通过将流量推回这种操作，从而得到新的流 。为什么要这么做呢？其实原因就是 因为对一条增广路不一定输入这条增广路的上限流量就能保证全局的最大流量 。再提高一个维度来看我们之前的思路，其实一直是“贪心”思想在引导我们加流和拆边操作，但是贪心并不能获得全局最大流量，这也是之前动态规划能够解决贪心对于全局最优解无法实现的问题 。\n既然我们无法得知如何取得全局最优解，有一种思路就是，继续增加可能情况。具体怎么加，其实只要对上面错误算法增加一个操作就可以：在第 2 步中，在边权减去流量之后，并对这条边再做一条反向边，并且容量变成对应消耗流量的相反数 。接着用图来解释：\n通过上述操作，我们又多找出了一条增广路（即图中红色的那条路），并且为 T 多增加了 1 个单位的流量，如此求得了最后的答案是 11。\n可能你会问，为什么这种做法是合理的，可以求得最终的结果呢？其实就涉及到我们上一篇所讲的 「最大流最小割定理」，这个证明我后续会放到 PC 端小册上，因为它属于延伸知识。而对于不想看枯燥的证明过程的朋友来说，你只要想明白这件事就可以了，看下图：\n以上，我们知道了怎么去求得最短路，下面来总结一下梳理后的算法：\n 搜索出一条增广路； 在这条路径中所有的边容量减去这条增广路的流量，并建立流量为增广路增加流量相反数的反向边； 返回操作一，如果没有增广路则得到答案。  这也就是本文标题中的 Ford-Fulkerson 最大流方法。\n如何代码实现查找增广路？ #  在这篇文章中，我们均使用 DFS 深度优先搜索来寻找增广路。这里直接给出代码：\n/** * 查找增广路 * @param c 当前节点 * @param t 汇点 * @param f 当前路径中的容量最小值 * @return */ int dfs(int c, int t, int f) { // 如果当前节点是汇点 t，直接返回容量最小值，即增广路增加的流量  if (c == t) { return f; } // 记忆化搜索染色  used[c] = true; // 遍历 c 节点下一个节点  for (int i = 0; i \u0026lt; G[c].size(); ++ i) { Edge \u0026amp;e = G[c][i]; // 如果这个节点未被访问到，并且其当前容量大于 0  if (!used[e.to] \u0026amp;\u0026amp; e.cap \u0026gt; 0) { // 访问到最深层节点  int d = dfs(e.to, t, min(f, e.cap)); if (d \u0026gt; 0) { // 当前边容器减少  e.cap -= d; // 反向边容量增加  G[e.to][e.rev].cap += d; return d; } } } return 0; } 其实这段代码也就是 Ford-Fulkerson 最大流方法 的核心代码，剩下的就是一个 while(true) 的迭代，直到找不到增广路，查找停止，得到最大流我们的代码结束。\n当我们理解了算法逻辑，代码实现起来也就异常的简单了！\n复杂度分析 #  由于我们使用深度优先搜索的情况，所以我们可以假设如果有一个图，其中有一条增广路的中间某一条边的容量是 1，但其实最后结果是不走流量的，但是在 DFS 的过程中每次还会先算到它。在这种情况下，假设我们图的最大流是 F ，则在这张图上 Ford-Fulkerson 方法就进行了 F 次的深度优先搜索。每一次搜索都会去搜 E 条边，所以其时间复杂度是 O(F ·|E|)。\n这里的最大流也许会非常大，所以使用 Ford-Fulkerson 方法会产生超级高的时间开销。所以你也明白了，后续的高效算法都是在查询增广路上做文章来优化 Ford-Fulkerson 方法。\n一些边沿知识 #  在这篇文章中，我们 一直称作 Ford-Fulkerson 方法，而不是 Ford-Fulkerson 算法，其实是因为 Ford-Fulkerson 给出了最大流问题中的三个重要思想 - 增广路、残余网络、反向边 。依赖于 Ford-Fulkerson 方法，后续的最大流算法如 Edmond-Karp 算法 、Dinic 算法 将会在 Ford-Fulkerson 基础上优化时间复杂度。\n另外提一句，Edmond-Karp 算法的作者 Manning Karp 因为在算法理论方面的巨大贡献，获得了 1985 年的图灵奖。\n计算机理论科学家 Manning Karp\n 关于 Manning Karp，最著名的就是他的《Karp 的 21 个 NP 完全问题》，有兴趣可以看 Wikipedia 对于这篇论文的介绍\n 相对于解决问题的算法而言，其思想程度更加重要，所以它是一种方法！\nFord-Fulkerson 方法的 代码实现 #  #include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;vector\u0026gt;#include \u0026lt;regex\u0026gt;using namespace std; const int MAX_V = 1e4 + 5; struct Edge { // 终点、容量、反向边  int to, cap, rev; Edge(int _to, int _cap, int _rev): to(_to), cap(_cap), rev(_rev) {} }; vector\u0026lt;Edge\u0026gt; G[MAX_V]; bool used[MAX_V]; void add_edge(int from, int to, int cap) { G[from].push_back(Edge(to, cap, G[to].size())); G[to].push_back(Edge(from, 0, G[from].size() - 1)); } /** * * @param c 当前节点 * @param t 汇点 * @param f 当前路径中的容量最小值 * @return */ int dfs(int c, int t, int f) { if (c == t) { return f; } used[c] = true; for (int i = 0; i \u0026lt; G[c].size(); ++ i) { Edge \u0026amp;e = G[c][i]; if (!used[e.to] \u0026amp;\u0026amp; e.cap \u0026gt; 0) { int d = dfs(e.to, t, min(f, e.cap)); if (d \u0026gt; 0) { e.cap -= d; G[e.to][e.rev].cap += d; return d; } } } return 0; } int main() { // 本文开篇时给出的示例  add_edge(0, 1, 16); add_edge(0, 3, 13); add_edge(1, 2, 12); add_edge(2, 3, 9); add_edge(2, 5, 20); add_edge(3, 1, 4); add_edge(3, 4, 14); add_edge(4, 2, 7); add_edge(4, 5, 4); int flow = 0; for (;;) { memset(used, 0, sizeof(used)); int f = dfs(0, 5, 1000); if (f == 0) { cout \u0026lt;\u0026lt; flow \u0026lt;\u0026lt; endl; // 23 验证通过  return 0; } flow += f; } } 总结 #  相信看了本文，已经开始对网络流中最大流问题有了更深的认识。但是上述实现的复杂度我们并不能在做题当中接受，所以接下来，我们将继续探讨更加高效的最大流算法。\n"});index.add({'id':5,'href':'/algo/docs/part2/ch03/1-range-max-query/','title':"RMQ（Range Maximum Query) 问题",'section':"Docs",'content':" 今天的算法可能有点难，但是如果我们只需要会使用 RMQ 问题的 ST 算法模板，这种程度就已经可以了！因为 RMQ 问题除了最优解的 ST 算法，剩下的都是高级数据结构的应用，例如：线段树、树状数组、Splay、Treap 甚至是主席树（额，我什么都没有暗示，业界就是这个名字）。好了今天我们从两个角度来解决这个问题。ST 算法和线段树。当然如果你对高级数据结构感兴趣，我也会在以后的文章中更新这个系列。\n 注意，学 RMQ 问题与图论没有直接关系，而是 Tarjan 算法中其中的一个重要步骤之一。再次验证了高级算法都是由基础的问题排列组合而来！🧐\n这篇文章我们只讲 RMQ 问题以及 RMQ 的最优解法 ST 算法。\n引子 #  RMQ 的英文是 Range Maximum(Minimum) Query，翻译过来其实就是区间求最值的意思。问题描述：对于长度为 n 的数列 A，回答若干询问   \\(RMQ(A, i, j)(i, j \u0026lt;= n)\\)  ，返回数列A中下标在 [i, j] 里的最小(大）值。\n在这个问题中，我们需要关注的是查询操作，查询可能是海量的，所以如果我们对数据进行快速的预处理，然后在外面处理后的数据结构中进行快速查询，其实就是最理想的状态。\n另外，注意是“在给定的区间内”，那么则说明区间在后续的查询时没有变化。所以我们可以理解成在区间确定后，我们其实已经拿到了所有查询情况的答案！对于这种对给定范围内求值的算法，我们对其归类为离线算法。（当然对应的还有在线算 法，后面讲 Tarjan 算法时我们再详谈）\n我们先来尝试下暴力：\nnums = [3, 2, 4, 5, 6, 8, 1, 2, 9, 7] def query(l, r): res = nums[0] for i in range(l, r + 1): res = max(res, nums[i]) return res 我们发现每一次查询都是一个  \\(O(n)\\)  的操作，在海量的查询面前，效率就十分低下了。或许你觉得  \\(O(n)\\)  还能接受？但是人总是喜新厌旧、择优选择的 🙄 。\nST 算法解决 RMQ 问题 #  ST 算法的全名是 Sparse Table Algorithm，中文一般管 Sparse Table 称作稀疏表。原理是基于二进制的倍增、动态规划思想的。笔者感觉还是有一定难度的。\n大概描述一下 ST 算法的两个步骤：\n1. 预处理 #  ST 算法原理上还是动态规划，我们用  \\(a(1...n) \\)  表示待查询的一组数，设  \\(f(i, j)\\)  表示从  \\(a(i)\\)  到  \\(a(i \u0026#43; 2^j - 1) \\)  这个范围内的最大值。也就是说  \\(a[i]\\)  为起点，连续  \\(2^j\\)  个数的最大值。由于元素个数为  \\(2^j\\)  个，所以从中间平均分成两部分，每一部分元素个数刚好为  \\(2^{j - 1}\\)  个，也就是说，把  \\(f(i, j)\\)  划分成  \\(f(i, j - 1)\\)  和  \\(f(i \u0026#43; 2^{j - 1}, j - 1)\\)  。\n我画个图来描述一下这个场景：\n整个区间的最大值一定是左右两部分最大值的较大值，满足动态规划的最优化原理（子状态影响父状态）。很显而易见的状态转移方程：\n \\[f(i,j)=max(f(i,j-1),f(i\u0026#43;2^{j-1},j-1)\\]  边界条件是：\n \\[f(i, 0)=a(i)\\]  这样我们就可以在  \\(O(nlogn)\\)  的复杂度内预处理 f 结果数组。\n我们举一个例子，还用上面暴力求职的数据：[3, 2, 4, 5, 6, 8, 1, 2, 9, 7] ， \\(f(1, 0)\\)  表示第 1 个数起，长度为  \\(2^0 = 1\\)  的最大值，其实就是 3。\n同理\n \\[f(1, 1) = max(3, 2) = 3\\]   \\[f(1, 2) = max(3, 2, 4, 5) = 5\\]   \\[f(1, 3) = max(3, 2, 4, 5, 6, 8, 1, 2) = 8\\]  规律就是 2 倍增区间。代码实现一下~\nnums = [3, 2, 4, 5, 6, 8, 1, 2, 9, 7] f = [[0 for _ in range(1, 40)] for _ in range(1, 31)] def rmq_initial(): n = len(nums) for i, num in enumerate(nums): f[i][0] = num for j in range(1, 31): for i in range(0, n): if i + (1 \u0026lt;\u0026lt; (j - 1)) \u0026gt;= n: break f[i][j] = max(f[i][j - 1], f[i + (1 \u0026lt;\u0026lt; (j - 1))][j - 1]) 查看一下预处理之后的  \\(f\\)  查询数组：\n[3, 3, 5, 8, 8, 0] [2, 4, 6, 9, 9, 0] [4, 5, 8, 9, 0, 0] [5, 6, 8, 9, 0, 0] [6, 8, 8, 8, 0, 0] [8, 8, 9, 9, 0, 0] [1, 2, 9, 0, 0, 0] [2, 9, 9, 0, 0, 0] [9, 9, 0, 0, 0, 0] [7, 0, 0, 0, 0, 0] 这是一个什么东西呢，我们先行（其实是 f 数组的第二个下标）来看：\n \\[\\left\\{\\begin{matrix} 3\u0026amp;3\u0026amp;5\u0026amp;8\u0026amp;8 \\end{matrix}\\right\\}\\tag{1}\\]  由于我们确定了第一个下标为 0，则这行的含义就是：\n \\[\\left\\{\\begin{matrix} max(3)\u0026amp;max(3, 2)\u0026amp;max(3, 2, 4, 5)\u0026amp;max(3, 2, 4, 5, 7, 8, 1, 2)\u0026amp;max(3, ..., 7) \\end{matrix}\\right\\}\\]  简单概括就是，对于 f[0][a] 来说，代表的就是 max(nums[0....0 + 2^a)。这是第二个下标的含义。对应的，对于 f[b][0] 来说，代表的就是 max(nums[b - 2 ^ b + 1 ... b]) 。好好理解这个数组含义，后面的查询操作就显而易见了。\n2. 查询操作 #  我们继续思考区间最大值问题，假设我要查询 [l, r] 这个区间，那么我们如果找到两个子区间，他们的并集精确覆盖到 [l, r] 是不是就满足要求了？\nST 由于使用2倍增，它的边界不好完美覆盖全部 case，所以我们在查询的时候需要简单的做交集操作来约束范围。在上面对于 f 数组的理解中，我们知道了 f 数组的横纵坐标分别代表首末的边界数值，我们的想法就是：为了满足所有区间均可求，我们使用两个范围，确定其最大值和最小值，只要能完全精准覆盖 [l, r]即可求得结果。这里我简单证明一下：\n我们假设一个中间量 k ，并满足：\n \\[2^k\\leq r-l\u0026#43;1\\leq2^{k\u0026#43;1}\\\\ k\\leq log_2{(r-l\u0026#43;1)}\\]  然后我们考虑一下 l 开始的  \\(2^k\\)  个数和以 r 结尾的  \\(2^k\\)  个数 这个区间是否可以覆盖我们的  \\([l, r]\\)  区间。当且仅当：\n \\[k\\geq log_2{(r-l\u0026#43;1)}-1\\]  取极限，我们令  \\(k = log(r - l \u0026#43; 1)\\)  ，那么在 f 数组中只需要查询：max(f[l][k], f[r - (1 \u0026lt;\u0026lt; k) + 1][k]) 就可以了，是不是很容易？🙄 （其实一点都不容易，但是一般教程都会这么写，我也就这么写，hhhhh）。\ndef rmq_query(l, r): k = math.log(r - l + 1) / math.log(2) return max(f[l][k], f[r - (1 \u0026lt;\u0026lt; k) + 1][k]) 如此，我们就通过了  \\(O(1)\\)  的方式完成了指定区间任意范围的 RMQ。对于海量数据查询的需求完成了最高度的优化。但是由于 ST 算法需要一个 2 倍增的预处理，所以整体的复杂度在 O(nlogn)。如此评估下来，其实如果查询量极少的情况下，我们用暴力法的时间开销  \\(O(n)\\)  是优于 ST 算法的，但是 ST 是在大量查询的场景下，所以算法也和业务技术方案一样，有适合于业务的，也有不适合于业务的，一切从业务出发来解决问题就好啦~\n我们掌握了以上方法，尝试着套着 ST 算法的模版，来 A 道题尝试一下，你会立马发现它的奇妙（能解决问题）！\nST 算法解决 RMQ 问题 #  我们来看一道 RMQ 的裸题：HDU-5443 The Water Problem\n这种题目分两步走，拍上模板，然后写逻辑！HDU 不支持 Python，我们用 C++ 写一版就好啦~\n#include \u0026lt;iostream\u0026gt;#include \u0026lt;cstdio\u0026gt;#include \u0026lt;math.h\u0026gt;#define maxn 1000000 + 4  using namespace std; int f[maxn][20]; // 模板 void rmq_initial(int n) { for (int j = 1; j \u0026lt; 21; ++ j) { for (int i = 0; i \u0026lt; n; ++ i) { if (i + (1 \u0026lt;\u0026lt; (j - 1)) \u0026gt;= n) break; f[i][j] = max(f[i][j - 1], f[i + (1 \u0026lt;\u0026lt; (j - 1))][j - 1]); } } } // 模板 int rmq_query(int l, int r) { int k = log(r - l + 1) / log(2); return max(f[l][k], f[r - (1 \u0026lt;\u0026lt; k) + 1][k]); } int main() { int T, n; cin \u0026gt;\u0026gt; T; while (T --) { scanf(\u0026#34;%d\u0026#34;, \u0026amp;n); for (int i = 0; i \u0026lt; n; ++ i) { scanf(\u0026#34;%d\u0026#34;, \u0026amp;f[i][0]); } rmq_initial(n); int l, r, q; scanf(\u0026#34;%d\u0026#34;, \u0026amp;q); while (q --) { scanf(\u0026#34;%d%d\u0026#34;, \u0026amp;l, \u0026amp;r); printf(\u0026#34;%d\\n\u0026#34;, rmq_query(l - 1, r - 1)); } } return 0; } 结尾 #  RMQ 问题其实还有很多解发，笔者比较常用的就是 ST 算法和线段树。但是 ST 算法无论从空间复杂度、时间复杂度还是代码量上来看，都优于线段树，但是 ST 算法往往只局限在 RMQ 问题，而具有区间操作的线段树的变化更加灵活，并且是在线查询，可以支持数据源的变化。所以在业务场景下，多变性和业务健壮性的工程角度来看，线段树是一个更加不错的选择。下一篇文章我们来讨论如何利用线段树来解决 RMQ 的问题。\n"});index.add({'id':6,'href':'/algo/docs/part4/ch03/3-perfect-matching/','title':"二分匹配的最大流思维",'section':"Docs",'content':"在之前的两篇文章中，我们讲述了「最大流问题」和「Ford-Fulkerson 最大流求解方法」，当然在阅读这篇文章之前，我需要你有以上两篇文章的基础，请在阅读上面两篇文章后再来进行阅读。这篇文章我们来讲述一个二分图匹配问题。并且将这个问题转化为最大流问题模型来解决。\n为了引出二分图匹配问题，我们首先给出一个实际问题的例子：\n计算机 CPU 指派问题 #  在我的 N 核计算机上有 K 个任务。每个任务在工作时都得霸占 CPU 一个完整的核心，并且每个 CPU 核心不是所有任务都能处理，只能处理其中几种任务。我们的问题是在一次处理过程中，最多能够处理的任务数是多少？\n上图中我描述了一组样例，在这组样例中 Task A 只能有 CPU X 和 CPU Y 来处理，Task B 只能由 CPU X 和 CPU Z 来处理，而 Task C 只能有 CPU Y 来处理。\n问题抽象与二分图最大匹配 #  其实上面对于样例的描述我们已经可以画出一个有向图了。我们将 Task 和 CPU 都转换成图节点：\n我们发现，这个图他可以分成左右两部分，并且左边这些节点相互之间没有相连的边，同样的右边节点也没有相连的边，所有的边都是左右两个部分之间的连接，对于这种特点的图，在图论中有一个专有的名词，二分图。\n而对于这个问题，我们需要求最多有多少个任务可以被处理，也就是说根据关系找到一种 Task 和 CPU 的配对方式，使得配对数量达到最大。这种二分图求最大匹配数量的问题，我们称之为二分图最大匹配问题。\n思考和转化问题 #  使用结果反向启发 #  我们可以考虑一种上方样例中的最大匹配方案，如下图所示就是一种情况：\n我们观察一下上面的答案，其实是删除了 A → Y 和 B → X 这两条边。有没有感觉这种删除边的操作我们之前也处理过呢？这里我们从最终的结果出发来启发你的思维，如果你没有发现什么玄机，我们再来做一个新的变化。\n赋权值量化图 #  第二种变化，我们对于原图的任意一条边增加权值为 1 。\n变化之后，我们只看左右两个部分，此时思考问题的角度就变成了从左边的节点集合到右边节点集合 最多可以保留几条边？换句话说，也就是从左到右流入的最大权值是多少？当然不是任意一条边都能保留，因为每一节点只能有一个出度和一个入度，这个条件也就确保了我们求得的结果是匹配数。\n既然我们需要保证左边集合中，每一个节点有且只有一个出度，而右边的节点有且只有一个入度，那么我们不妨将这个题目再次进行转换，我们将边权值定义为流量容量，且节点也增加权值，且定义为当前节点的流量值。\n此时，我们将问题 变成了一个多限制流量源点（A、B、C）多汇点（X、Y、Z）的最大流问题 ！但是我们并不会求多限制源点多汇点的最大流，因为我们没有学过具体的方法。但是我们发现，这些源点流量是被限制的，可不可以通过一个方法让这些点自然带上这些限制的流量？当然有，加一条有容量的边！\n我们在图的两边分别增加了一个超级源 S 和超级汇 T 两个点，其中 S 具有无穷流量。然后分别增加了 S 到 A、B、C 的边，X、Y、Z 到 T 的边，且这些边的容量都是 1。通过容量我们限制了 A 、B、C 的流量都是 1，并且由于都是以一个单位统计，则流入 T 的流量结果就是最大的匹配数 。\n此时这个问题已经转化成了之前介绍的 最大流问题 。是不是十分神奇呢~\nFF 最大流解决二分图最大匹配问题 #  经过了一系列花活，我们将二分图最大匹配问题，又转换成了之前的网络流的最大流问题。此时我们掏出之前学习过的 Ford-Fulkerson 最大流求解方法来实现以下即可：\n#include \u0026lt;iostream\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;vector\u0026gt;using namespace std; const int MAX_V = 1e4 + 5; struct Edge { // 终点、容量、反向边  int to, cap, rev; Edge(int _to, int _cap, int _rev): to(_to), cap(_cap), rev(_rev) {} }; vector\u0026lt;Edge\u0026gt; G[MAX_V]; bool used[MAX_V]; void add_edge(int from, int to, int cap) { G[from].push_back(Edge(to, cap, G[to].size())); G[to].push_back(Edge(from, 0, G[from].size() - 1)); } /** * * @param c 当前节点 * @param t 汇点 * @param f 当前路径中的容量最小值 * @return */ int dfs(int c, int t, int f) { if (c == t) { return f; } used[c] = true; for (int i = 0; i \u0026lt; G[c].size(); ++ i) { Edge \u0026amp;e = G[c][i]; if (!used[e.to] \u0026amp;\u0026amp; e.cap \u0026gt; 0) { int d = dfs(e.to, t, min(f, e.cap)); if (d \u0026gt; 0) { e.cap -= d; G[e.to][e.rev].cap += d; return d; } } } return 0; } int main() { // A, B, C 为节点 0, 1, 2  // X, Y, Z 为节点 3, 4, 5  // S, T 为节点 6, 7  // 题目描述的 A, B, C 和 X, Y, Z 的关系  add_edge(0, 3, 1); add_edge(0, 4, 1); add_edge(1, 3, 1); add_edge(1, 5, 1); add_edge(2, 4, 1); // 模拟超级源 S 点  add_edge(6, 1, 1); add_edge(6, 2, 1); add_edge(6, 3, 1); // 模拟超级汇 T 点  add_edge(3, 7, 1); add_edge(4, 7, 1); add_edge(5, 7, 1); // 求最大流  int flow = 0; for (;;) { memset(used, 0, sizeof(used)); int f = dfs(6, 7, 1); if (f == 0) { cout \u0026lt;\u0026lt; flow \u0026lt;\u0026lt; endl; // 3 验证通过  return 0; } flow += f; } } 总结 #  网络流的神奇之处就在于，我们可以将其他类型的题目通过图抽象、加点权约束，从而转换成网络流中的经典问题。这篇将 二分图最大匹配 转换成 最大流问题 的思维过程，想必会让你对图算法又了新的认识。算法题目的考察从广义上来讲，就是在考察你 是否能将这个问题对应到一个你熟悉的求解模型和方法上 ，如果你抽象得当，你就可以利用已有的算法，去高效的求解这个问题。\n“万物皆可网络流”，真正有趣的才刚刚开始！\n"});index.add({'id':7,'href':'/algo/docs/part4/ch03/1-maximum-flow-basic/','title':"初识最大流问题",'section':"Docs",'content':"在阅读之前先来提出几个问题。如果这些问题你都知道答案那就可以直接跳过，期待下一篇文章了：\n 什么是网络流模型？ 网络流有哪些经典问题？ 哪些问题能转化成网络流问题？  这篇文章会用一个描述的方式来先认识这些概念问题，而代替很多书上的符号标记。\n流网络与最大流问题 #  首先网络流问题都是建立在流网络上的。这一点不要弄混，所谓流网络首先它是一个有向图，并且图中每条边都有一个非负的容量值。这个容量值我们暂时可以理解成边的权，但是这个权有着它自身的含义。我们来针对流网路举一个例子：\n 假设有这么一个例子，这次 2019-nCoV 疫情让口罩变成了稀缺资源。所以，全国各地都在为武汉捐献物资。假设现在因为种种原因，我们只能通过地面线路来运输口罩物资，并且每一条线路是有流量限制的。假设不考虑运输速度，并且源点 S （杭州）的口罩物资产量是足够多的，我们需要求解汇点 T（武汉）在不计速度的情况下能收到多少物资？\n 上面的流网络可能我们很难一眼看出答案，那么我们先简化一下场景。我们删几条边来看下这个问题：\n对于这个流网络，我们可以轻松的获得汇点 T 的最大流量。\n因为在这个图中，只有两条路径，本别是 S → A → B → T 和 S → C → D → T 两条路径来输送流量，前者最大流量是 12 ，后者是 4，所以最大流量总和是 16。\n这其实就是流网络的一个经典问题模型 —— 最大流问题（Maximum-Flow Problem）。\n网络流问题的一些关键概念 #  在上述场景中，我们讲述了最大流问题是在研究什么样的问题。接下来，我们来定义一些网络流问题当中的一些关键概念。这些概念有助于理解以后学习网络流中出现的各种名词。\n什么是增广路？ #  首先我们来说什么是增广（Augmenting）？在最大流问题中，我们每次找的一条可以增加汇点流量的路径，即在网络中找出一条可以到汇点 T 的道路，并且求出这条道路所有边剩余容量的最小值 d，并在上所有边的流量都加上这个 d，这个过程就是增广。而增广路（Augmenting Path）就是这条可以给 T 带来更多流量的路径。\n比如上图中，S → A → B → T 和 S → C → D → T 就是两条增广路。\n最大流中的增广路定理 #  由上面的定义，可以知道当一个流网络中，仍旧存在增广路的时候，此时汇点 T 是可以继续增加流量的，所以此时的情况肯定没有达到最大流。\n反之，当且仅当网络中不存在 S-T 有增广路时，此时的流是从 S 到 T 的最大流。这个就是最大流中的增广路定理。\n什么是残余网络？ #  继续用上文中的那个场景，当已经选出 S → A → B → T 这条增广路的时候，我们将已经消费的流量记录在每条边流量的左方。像这种已经消费部分流量的网络，我们将其叫做残余网络（Residual network）。\n最小割最大流定理 #  首先先了解一下什么是最小割，对于一个有向图，已知原点 S 和汇点 T。当我们拆掉图中的某几条边使得没有从 S 到 T 的通路，并保证所减的边的权重和最小。\n在上面的例子中，相信大家很快就能找到这两条边，那就是   \\(AB\\)  和  \\(DT\\)  。我们用图来说明一下：\n当通过割线 l 来删除  \\(AB\\)  和  \\(DT\\)  ，此时发现起点 S 已经无法走到汇点 T 了。我们将这样的集合划分  \\((S, T)\\)  称为  \\(s-t\\)  割，且具有容量定义：\n \\[c(S, T)=\\sum_{u \\in S,v \\in T}^{} c(u, v)\\]  这个式子左边的意思就是我们将这个图通过割线的分割后，就出现了 S, T 两部分，即包含起点 S 的部分和包含汇点 T 的部分。\n而式子右边的意思是我们从 S 部分任取一个点，从 T 部分任取一个点，假设 uv 是一条边，则我们把这种情况的所有边容量加和。这里的加和要以 S 到 T 为正向，则反向的容量就是负权。根据这种描述，我们就可以将图转化成以下模型：\n假设 f(u, v) 代表是从 u 节点到 v 节点流过的流量，那么对于上面 S、T 两个虚拟的集合节点来说，肯定就有以下公式：\n \\[f(S, T) \\leq c(S,T)\\]  而流量什么时候到达最大值 c(S, T) 呢，我们上文说过，当没有其他增广路的时候。所以我们说，在最大流问题中，一个流网络的最大流等于其最小割。\n小结 #  以上讨论中，我们已经学习了在网络流当中的一些相对重要的定义。根据上面的分析，你应该清楚如果我们想解决最大流问题，首先应该实现找到增广路的算法。\n但是只找到增广路就可以解决了吗？你可以用上文提到的没有删减边的例子再试试。\n"});index.add({'id':8,'href':'/algo/docs/part2/ch01/1-quick-pow/','title':"加速幂运算",'section':"Docs",'content':"幂运算是我们平时写代码的时候最常用的运算之一。根据幂运算的定义我们可以知道，如果我们要求 x 的 N 次幂，那么想当然的就会写出一个 N 次的循环，然后累乘得到结果。所以我们要求幂运算的复杂度仍旧是   \\(O_{(N)}\\)  ?\n那么有没有一种更快的方法呢？\n这里给出一种在计算机领域常用的快速幂算法，又叫蒙哥马利幂（Montgomery reduction）算法，将  \\(O_{(N)}\\)  降为  \\(O_{(logN)}\\)  。\n我通过例子来讲解这个优化过程：\n假设我们要算 x 的 n 次幂，使用累乘来编写代码：\nres = 1 for i in range(n): res *= x 好的，我们已经完成了  \\(O_{(N)}\\)  的解法。\n二进制拆分 #  为了优化这个算法，我们接下来进行数学推导：\n我们继续思考当 N = 10 这个具体场景，我们可以把 10 写成二进制来表示 1010(BIN)，然后我们模拟一次二进制转十进制的过程（复习一下大学知识）：\n \\[10 = 2^3 \\times \\underline{1} \u0026#43; 2^2 \\times \\underline{0} \u0026#43; 2^1 \\times \\underline{1} \u0026#43; 2^0 \\times \\underline{0}\\]  我用下划线把二进制的 1010 标识出来，这样大家就可以发现二进制和十进制转换时的代数式规律。\n继续回想刚才的场景，那么我们求 x 的 10 次幂，则式子我们可以写成这样：\n \\[x^{10} = x^{2^3 \\times 1 \u0026#43; 2^2 \\times 0 \u0026#43; 2^1 \\times 1 \u0026#43; 2^0 \\times 0}=x^{2^3 \\times 1}\\times x^{2^2 \\times 0}\\times x^{2^1 \\times 1}\\times x^{2^0 \\times 0}\\]  我们按照二进制低位到高位从左往右交换一下位置：\n \\[x^{10}= (x^{2^0 \\times 0})(x^{2^1 \\times 1})(x^{2^2 \\times 0})(x^{2^3 \\times 1})\\]  我们关注相邻的两项，如果我们不考虑幂指数的 *0 和 *1 ，我们只看前半部分，会发现有这么一个规律：\n \\[\\frac{x^{2^k}}{x^{2^{k-1}}}=\\frac{x^{2^{k-1}*2}}{x^{2^{k-1}}}=\\frac{(x^{2^{k-1}})^2}{x^{2^{k-1}}}=x^{2^{k-1}}\\]  也就是说，不考虑幂指数的 *0 和 *1 右式，左式每次只要每次乘以自身，就是下一项的左式。在我们的例子中其实就是。\n这里我们单独看第三项和第二项的关系\n \\[x^{2^{2}}=(x^{2^1})^2 \\]  用编程思维来考虑这个问题，只要我们从 x 开始维护这么一个左式，每一次迭代都执行 x *= x，然后每次遇到右边是 *1 的情况，就记录一下 res *= x 是不是就能模拟咱们二进制拆分的计算思路了呢？\n编程实现一下 x 的 10 次方 #  我们用上面的思路，通过代码来计算一下 2 的 10 次方，答案应该是 1024。\n#include \u0026lt;iostream\u0026gt;using namespace std; int main() { int n = 10; // 幂指数，下面通过二进制拆分成 1010  int x = 2; // 底数  int res = 1; // 累乘的答案  while (n) { // 去除二进制的最低位，也就是上面推导中的右式，如果 n \u0026amp; 1 == 1，说明是 *1  if (n \u0026amp; 1) { // 如果是 *1，则根据我们观察出来的规律，对维护的结果做累乘  res *= x; } // 转换到下一位  x *= x; // 二进制右移一位，目的是取到下一个低位二进制  n \u0026gt;\u0026gt;= 1; } cout \u0026lt;\u0026lt; res \u0026lt;\u0026lt; endl; // 1024  return 0; } 是不是发现非常的简单！我们至此已经实现了快速幂算法。我们将 n, x 做成参数，编写一个快速幂的方法：\n#include \u0026lt;iostream\u0026gt;using namespace std; int qpow(int x, int n) { int res = 1; while (n) { if (n \u0026amp; 1) res *= x; x *= x; n \u0026gt;\u0026gt;= 1; } return res; } int main() { cout \u0026lt;\u0026lt; qpow(2, 10) \u0026lt;\u0026lt; endl; // 1024  cout \u0026lt;\u0026lt; qpow(4, 2) \u0026lt;\u0026lt; endl; // 16  cout \u0026lt;\u0026lt; qpow(5, 3) \u0026lt;\u0026lt; endl; // 125  cout \u0026lt;\u0026lt; qpow(10, 6) \u0026lt;\u0026lt; endl; // 1000000  return 0; } 复杂度 #  通过上面对幂指数的拆分，发现快速幂只需要循环拆分的项数就可以完成整个幂运算。\n我们不妨设求 x 的 N 次方，并且令 x 的所有二进制位都为 1，就可以得到下面这个等式：\n \\[2^0\u0026#43;2^1\u0026#43;...\u0026#43;2^k=N\\]  那么其实，k 就是计算机需要计算的次数，也就是时间复杂度。套入公比是 1 的等比数列前 k 项和来反推 k 的大小：\n \\[\\frac{a_1(1-q^k)}{1-q}=2^k-1=N \\\\ k=log_2{N-1} \\Rightarrow O(logN)\\]  好了，这就是快速幂的全部内容了。你可以使用这道题的知识来求解 LeetCode 372. Super Pow 。下一篇文我们来手把手 AC 这题。\n"});index.add({'id':9,'href':'/algo/docs/part2/ch01/2-quick-pow-mod/','title':"快速幂取模算法",'section':"Docs",'content':"上一篇文章我们讲了如何将幂运算优化到   \\(O(logN)\\)  的方法。这一篇来研究一下，快速幂算法与取模运算是如何结合的。\n取余和取模 #  首先我们要知道在编程语言中有 % 这么一个操作符，在各大编程书中称之为“取余运算”。在程序设计和抽象数学领域，我们管这个操作叫做：取模运算。\n下面以整型 a 和 b 两个变量举例，在我们常说的取余运算中，其算法会分成以下的两个步骤：\n 求整数商：c = a / b 求余数：r = a - c * b  取模与取余不同在于第一步，求余在整除的时候是往 0 方向逼近，而取模是往负无穷方向逼急。这样就造成了在对负数进行取模运算的差异。所以在计算 -7 % 4 的时候，求余运算的结果是 -3，而取模运算是 1。\n/// 第一步：求整数商 // 求余运算 -7 / 4 = -1 (逼近 0 ) // 求模运算 -7 / 4 = -2 (逼近负无穷) /// 第二步： // 求余运算 -7 - -1 * 4 = -7 + 4 = -3 // 求模运算 -7 - -2 * 4 = -7 + 8 = 1 当然，逼近方向其实不影响其他的运算规律，因为任意的 a % b，对于给定的 a 和 b ，计算结果一定是一个确定的值。所以我们只需了解这两种计算的区别就可以。\n不同语言的 % 运算符表现 #  Python #  % 在不同的语言中，可能会表现出不同的运算。例如在 python 中，% 是取模运算，另外整除的表现也是像负无穷无限逼近，以及 divmod 也是求模的表现。（以下是使用 iPython 的调试结果）\nIn [1]: -7 % 4 Out[1]: 1 In [2]: divmod(-7, 4) Out[2]: (-2, 1) In [3]: -7 // 4 Out[3]: -2 C/C++/Java/Swift #  % 在 C/C++/Java 中均为求余运算的表现。\n// C++ int main() { cout \u0026lt;\u0026lt; -7 / 4 \u0026lt;\u0026lt; endl; // -1  cout \u0026lt;\u0026lt; -7 % 4 \u0026lt;\u0026lt; endl; // -3  return 0; } // Java public class TestMod { public static void main(String []args) { System.out.println(-7 / 4); // -1  System.out.println(-7 % 4); // -3  } } // Swift print(-7 / 4) // -1 print(-7 % 4) // -3 只有掌握了在各个语言中的不同表现，我们才能在解题的时候知道具体的运算流程，否则当遇到求模处理时，由于语言的迁移使用而造成了想当然的情况。\n求模运算的规律 #  这里我直接给出规律，如果想看证明请自行 Google。\n(a + b) % p = (a % p + b % p) % p (a - b) % p = (a % p - b % p + p) % p (a * b) % p = (a % p * b % p) % p a ^ b % p = ((a % p)^b) % p 结合快速幂算法 #  终于来到了最关键的地方，结合快速幂算法后会有什么影响呢？\n其实在我们日常做题中，你会看到输出结果对 xxxx 取模。这种题目可能是有两种考察方向:\n 在原算法的基础上，多一个取模运算来考察你对取模运算规律的掌握； 大数据时数据增长太快，64 位甚至 128 位的整形无法表示；  对应的，我们快速幂的题目就是这样，假设让你求 a 的 b 次方，当 a = 10 且 b = 20 次方就已经超过了 64 位 Int 类型的范围（ \\(2^{64}\\)  次方约等于 1.84 * 10^19）。\n所以，接下来我们要把求模运算也加入到快速幂运算中，我们先来观察上一篇文中所使用到的快速幂算法：\nint qpow(int x, int n) { int res = 1; while (n) { if (n \u0026amp; 1) res *= x; // 关注点 1  x *= x; // 关注点 2  n \u0026gt;\u0026gt;= 1; } return res; } 我们来看关注点 1 和关注点 2 两个地方，分析得到这两个结论：\n 我们的快速幂算法其实并没有真正的优化乘法效率，而是通过二进制拆分，从而优化了乘法运算的次数，具体的表现就是 x *= x 来扩大乘子的基数； 在计算 res 的时候，res *= x 仍旧是一个累乘的过程，唯一的变化就是 x 在由于 x *= x 逐渐变化。这两个式子结合起来，其实就是 res 不断的去累乘多个 x 。  有了这两点分析，我们就可以套用求模运算规律了。\n(a * b) % p = (a % p * b % p) % p  我们在所有乘法表达式的地方增加求模运算，其实反映出来的结果就是 res 不断累乘时候每一项都做一次求模运算。\n有着以上思路我们来修改代码：\nint qpow(int x, int n, int m) { int res = 1; while (n) { if (n \u0026amp; 1) res = res * x % m; x = x * x % m; n \u0026gt;\u0026gt;= 1; } return res; } int main() { cout \u0026lt;\u0026lt; qpow(10, 3, 997) \u0026lt;\u0026lt; endl; // 3  cout \u0026lt;\u0026lt; qpow(10, 2, 997) \u0026lt;\u0026lt; endl; // 100  return 0; } 好了，有了这两篇文章的知识点，你可以自己来尝试 [LeetCode-372] 超级次方 这道题目了。\n"});index.add({'id':10,'href':'/algo/docs/part2/ch02/1-eratos-sive/','title':"快速素数筛法",'section':"Docs",'content':"本文的内容实用而且简单！素数问题是从来都是数学家热衷探索的领域，也是程序设计竞赛和 LC 中，解决数论相关问题的基础，下面本文介绍如何更科学地筛素数和一些相关的小知识。\n首先从定义来说， **素数，指整数在一个大于 1 的自然数中，除了1和此整数自身外，没法被其他自然数整除的数。**那么首先我们可以根据定义来写出我们的最暴力求解素数的程序\n暴力统计素数 #  假设有 n 个数，我们的方法很简单，判断每个数是否有其他因子，如果有则不是素数，时间复杂度为 O(nlogn)。\n我们以的题目 《LeetCode-204 计数质数》 为例，题目描述：\n统计所有小于非负整数 n 的质数的数量。\n输入: 10\n输出: 4\n解释: 小于 10 的质数一共有 4 个, 它们是 2, 3, 5, 7 。\n 我们可以写出如下程序：\nclass Solution: def countPrimes(self, n: int) -\u0026gt; int: ans = 0 for i in range (2, n): flag = True # 只需要检查小于等于sqrt(n)的因数就可以了,因为大于的那部分一定对应着一个小于sqrt(n)的因数 for j in range(2, int(math.sqrt(i)) + 1): if 0 == i % j: flag = False break if flag: ans += 1 return ans 功能上来说，我们的已经完全实现对素数进行计数，但是提交结果超出时间限制。所以接下来我们要改进一下算法。\nEratosthenes 筛法 #  Eratosthenes 筛法进行的是打表，也就是平时说的离线操作，当查询量比较大的时候，我们往往采用这种方法进行离线操作处理；该算法的内容是：首先假设 n 个数全部都是素数，然后从 2 开始，把每一个数的倍数都剔除并标记成合数（因为合数肯定是有素因子的），这样列表中保存着的都是没有素因子的数，就是我们想要的质数了。\n下面我们对之前的代码进行优化\nclass Solution: def countPrimes(self, n: int) -\u0026gt; int: n = max(2, n) #处理输入数字为0的情况 is_prime = n * [1] is_prime[0] = is_prime[1] = 0 for i in range(2, n): if is_prime[i]: for j in range(2, n): if i * j \u0026gt;= n: break is_prime[i * j] = 0 return sum(is_prime) 显然这道题目比较简单，但是我们还能不能继续对算法进行优化呢？\n很明显，很多合数有不止一个素因子，这样上述算法进行了一些重复性的计算，比如对数字 6 来说，素因子 2 和 3 在筛选过程中都对他进行了剔除标记，也就是说，所有 6 的倍数，至少都被 2 和 3 进行了重复的剔除。\n欧拉筛法 - 线性筛 #  回忆一下，在我们的暴力算法中，为了简化计算，我们只对小于等于 sqrt(n) 的数进行取余检查；这里可以采取类似但是更简洁的办法，只要保证每个合数只会被他的最小素因子筛掉就可以了，所以我们优化算法的核心：\n 寻找并保存当前的素数； 对每个数的从小到大的素数次倍数进行标记，当发现这个数的素因子后停止（这也就保证每个数都是被最小素因子筛掉的）；  我们以 i = 21 为例，此时素数表为：2, 3, 5, 7, 11, 13, 17, 19\n第一轮，标记 2 的倍数，42；\n第二轮，标记 3 的倍数，63，这时候我们发现 21 的最小素因子是 3\n  \\[21=3^1\\times 7^1\\]  也就是说 63 必定是被 21 的最小素因数 3 来标记的，后边的所有素数次倍数也都至少可以被 3 标记，就是我们刚才说的重复操作，所以可以选择停止后面的操作节省时间。\n这里额外需要一个列表保存已经筛选的素数，下面是我们优化后的代码，时间复杂度为 O(n)。\nclass Solution: def countPrimes(self, n: int) -\u0026gt; int: n = max(2, n) primes = n * [0] cnt = 0 is_prime = n * [1] is_prime[0] = is_prime[1] = 0 for i in range(2, n): if is_prime[i]: # 保存已经筛出的素数 primes[cnt] = i cnt += 1 for j in range(cnt): # 如越界则停止 if primes[j] * i \u0026gt;= n: break # 标记 i 的素数次倍数 is_prime[primes[j] * i] = 0 # 如遇到 i 的素因数，则停止  if i % primes[j] == 0: break return sum(is_prime) 一个要点 #  这段代码怎么解释？ #  if i % primes[j] == 0: break 这句代码保证了每个数最多被筛一次，将时间复杂度降到了线性。证明如下：\n因为 primes[] 数组中的素数是递增的，当 i 能整除 prime[j] 的时候，则 i * prime[j + 1] 这个合数可能能被 prime[j] 乘以某个数筛掉。\n因为 i 中含有 prime[j] 且 prime[j] 比 prime[j + 1] 小，即 i = k * prime[j] ，那么 i * prime[j + 1] = (k * prime[j]) * prime[j + 1] = k' * prime[j]，后面的素数同理。所以不用继续筛下去了。\n隐藏，在满足 i % prime[j] == 0 这个条件之前以及第一次满足该条件时，prime[j] 一定是 prime[j] * i 的最小因子。\n复杂度对比 #  Eratosthenes 筛法的时间复杂度理论值是  \\(O(Nlog(logN))\\)  ，而线性筛的理论复杂度是  \\(O(N)\\)  。可是我通过实际的时间统计，发现 Eratosthenes 筛法更快且更稳定（一脸黑人问号）🌚？如果有读者知道这是怎么一回事，欢迎下方留言。\n画图代码：\nfrom matplotlib import pyplot as plt x = [] y1, y2 = [], [] for i in range(0, 1000000, 50000): x.append(i) y1.append(eratosthenes_time(i)[1]) y2.append(euler_time(i)[1]) plt.title(\u0026#39;Time Complexity Analysis\u0026#39;) plt.plot(x, y1, color=\u0026#39;green\u0026#39;, label=\u0026#39;eratosthenes_sieve\u0026#39;) plt.plot(x, y2, color=\u0026#39;red\u0026#39;, label=\u0026#39;euler_sieve\u0026#39;) plt.xlabel(\u0026#34;Parameter Range\u0026#34;) plt.ylabel(\u0026#34;Time Complexity(s)\u0026#34;) plt.legend() # 显示图例 总结 #  所以，我们在求解筛素数表的题目，只要使用 Eratosthenes 筛法就可以解决我们 80% 的问题。这种方法即容易理解，又比传统的暴力筛效率提升很多。\n"});index.add({'id':11,'href':'/algo/docs/part2/ch02/3-ext-euclidean/','title':"扩展欧几里得算法",'section':"Docs",'content':"一道头条的笔试题 #  上个月在脉脉上看到一道头条校招的笔试题，看评论说是“地狱难度”的，我们通过这道题来延伸说一下。先来看下这题的题面：\n有一台用电容组成的计算器，其中每个电容组件都有一个最大容量值（正整数）。\n对于单个电容，有如下操作指令：\n指令1：放电操作-把该电容当前电量值清零；\n指令2：充电操作-把该电容当前电量补充到最大容量值；\n指令3：转移操作-从电容 A 中尽可能多的将电量转移到电容 B ，转移不会有电量损失，如果能够充满 B 的最大容量，那剩余的电量仍然会留在 A 中。\n现在已知有两个电容，其最大容量分别为 a 和 b，其初始状态都是电量值为 0，希望通过一些列的操作可以使其中某个电容（无所谓哪一个）中的电量值等于 c （c也是正整数），这一些列操作所用的最少指令条数记为 M，如果无论如何操作，都不可能完成，则定义此时 M= 0。\n显然对于每一组确定的 a，b，c，一定会有一个 M 与之对应。\n 这里需要输入的是 a、b、c ，给出两个样例，例如 a = 3, b = 4, c = 2 ，则最少需要 4 个指令完成。解释：设最大容量为 3 的是 A 号电容，另一个是 B 号电容，对应的操作是 （充电 A）=\u0026gt; （转移 A -\u0026gt; B） =\u0026gt; （充电 A）=\u0026gt; （转移 A -\u0026gt; B） ，这样 A 就是目标的 2 电量。第二个样例 a = 2, b = 3, c = 4，由于 a 和 b 都无法到大目标电量 4，所以输出 0 代表无解。\n这道题我们拿到以后，第一反应就是模拟三个指令，然后使用 BFS 广度优先搜索来搜出答案，只要任意情况到达目标的 c 值就停下来。但是题目中给出了数据量   \\(0 \\leq a, b, c \\leq 10^9\\)  ，这个数据量约束了我们无法使用暴力搜索来求解。\n简要分析 #  首先从笔试的角度来分析，由于笔试时会有数据范围的测试，这道题给出的数据范围大概是这样：\n0 \u0026lt; a, b, c \u0026lt; 10^5 (50%) 0 \u0026lt; a, b, c \u0026lt; 10^7 (30%) 0 \u0026lt; a, b, c \u0026lt; 10^9 (20%) 所以如果没有任何的思路和数论基础，我建议使用 BFS 直接写一版暴力，最少可以通过  \\(\u0026gt; 50\\%\\)  的数据，从而拿到一定的分数。（其实这就是 OI 得分赛制，没有思路先暴力抢分）。\n下面我们来分情况讨论这个问题：\n情况一\n样例已经给出了一种边界情况，即当  \\(c \u0026gt; max(a, b)\\)  ，这种情况是无法使得 A 和 B 的电量达到 c 的。直接输出 0。\n情况二\n还有一种我们可以直接想到的情况，当 a = c 或者 b = c 的时候，只进行一次充电操作就可以完成，直接输出 1。\n情况三\n接下来我们考虑一般情况，即需要满足以下前提条件：\n \\[c \u0026lt; max(a, b) \\\\ c \\neq min(a, b)\\]  我们将这个问题换一个思路转化一下假设给出的 a 、b、 c 一定有解，那么我们来设置对 A 做了 x 次的充（放）电，对 B 做了 y 次的充（放）电，并且做了 k 次的操作三。如果将 A、B 当做一个大电容来看这个电容只有充放电 a 单位、充放电 b 单位这 4 种操作。那么我们就可以列出一个关系式：\n \\[ax\u0026#43;by=c\\]  由于 a、b 为非负整数，又因为前提条件  \\(c \u0026lt; max(a, b)\\)  ，则 x 和 y 符号相反。\n暂且，我们先不管做了几次操作三，先只考虑充放电问题，那其实就是已知 a、b、c，我们在给定范围内求解 x 和 y 的解就可以了。那么这个问题我们要如何求解呢？这就是扩展欧几里得算法所要解决的问题。\n扩展欧几里得算法（Extended Euclidean） #  在推导上述问题的求解算法之前，我们需要先了解以下几个概念知识。\n丢番图方程（Diophantine Equation） #  丢番图方程指的是：未知数个数多于方程个数，且未知数只能是整数的整数系数方程或方程组。例如以下式中， \\(a, b, c\\)  都为整数:\n \\[a_1x_1^{b_1}\u0026#43;a_2x_2^{b_2}\u0026#43;......\u0026#43;a_nx_n^{b_n}=c\\]   关于代数学鼻祖丢番图（Diophantus）除了有《算数》这本开山巨作之外，还有一个好玩的数学题目墓志铭，有兴趣可以自己了解。\n 裴蜀定理（Bézout\u0026rsquo;s identity） #  在数论中，裴蜀定理是一个关于最大公约数的定理。这个定理说明了对于任意整数 a、b 和他们的最大公约数 d，关于未知数 x 和 y 的线性丢番图方程：\n \\[ax\u0026#43;by=m\\]  有解，当且仅当 m 是 d 的倍数时。这个等式也被称为裴蜀等式。\n裴蜀等式有解时必然有无穷多个整数解，每组解 x 、y 都称之为裴蜀数，可用辗转相除法求得。\n辗转相除法实现扩展欧几里得算法 #  既然说可以用辗转相除法来解决这个问题，那么我们先来说明一下如何通过辗转相除法来求二元一次线性丢番图方程。\n辗转相除法过程\n以 23x + 17y = 1 为例，我们来求 GCD(23, 17)：\n \\[23 = 17 \\times 1 \u0026#43; 6\\\\ 17 = 6 \\times 2 \u0026#43; 5 \\\\ 6 = 5 \\times 1 \u0026#43; 1 \\\\ 5= 1 \\times 5 \u0026#43; 0 \\\\1 = 0 \\times0\u0026#43;1\\]  改写成余数形式\n将等式右边的第一项移项：\n \\[23 \\times1\u0026#43;17\\times -1=6 \\ \\ \\ \\ \\ \\ (1) \\\\ 17 \\times 1 \u0026#43; 6 \\times -2=5 \\ \\ \\ \\ \\ \\ \\ \\ (2)\\\\ 6 \\times 1 \u0026#43; 5 \\times -1 = 1\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ (3) \\]  反向带入原式\n带下划线的 6 和 5 会使用 (1) 和 (2) 两个式子反向带入，形同换元：\n \\[\\begin{aligned} 1 =\\ \u0026amp; \\underline{6} \\times 1 \u0026#43; \\underline{5} \\times -1 \\\\ =\\ \u0026amp; (1) \\times 1 \u0026#43; (2) \\times -1 \\\\ =\\ \u0026amp; (23 \\times 1 \u0026#43; 17 \\times -1) \u0026#43; [17 \\times 1 \u0026#43; (23 \\times 1 \u0026#43; 17 \\times -1)\\times -2]\\times-1 \\\\ =\\ \u0026amp; 23 \\times 3\u0026#43;17 \\times -4 \\\\ =\\ \u0026amp; 23x\u0026#43;17y \\end{aligned}\\]  所以反解得，x = 3, y = -4 是上述二元一次线性丢番图方程的一组解。\n扩展欧几里得算法证明 #  来观察一下辗转相除法的最后两个式子，终止条件是：\n$$5= 1 \\times 5 + 0 \\ 5=0 \\times 5+5$$\n当且仅当第二个式子为 0 的时候停止这个递归运算。如何延伸到一般情况呢？我们将待求变量设为字母来尝试一下。假设此时，我们要求 an 和 bn 为系数的二元一次线性丢番图方程的系数，即待求方程：\n$$a_nx+b_ny=gcd(a_n, b_n)$$\n根据上述的改写余数形式，我们可以列出式一（| 是整除的意思）：\n$$\\begin{aligned}a_0 \\times 1 - b_0 \\times (a_0|b_0) =a_0\\ mod\\ b_0\\end{aligned}$$\n假设未到达最终的终止条件，则有：\n \\[\\begin{aligned}a_1 \\times 1 - b_1 \\times (a_1|b_1) =a_1\\ mod\\ b_1\\end{aligned}\\]  第二个式子中我们可以发现：\n \\[\\begin{aligned}a_1\u0026amp;=b_0 \\\\ b_1\u0026amp;=a_0 \\ mod \\ b_0=a_0 \\times 1 - b_0 \\times (a_0|b_0)\\end{aligned}\\]  同理，第 n 个式子中有：\n \\[\\begin{aligned}a_n \\times 1 - b_n \\times (a_n|b_n) \u0026amp;=a_n\\ mod\\ b_n\\\\a_{n}\u0026amp;=b_{n-1} \\\\ b_{n}\u0026amp;=a_{n-1} \\times 1 - b_{n - 1} \\times (a_{n-1} | b_{n-1}) = a_{n-1}\\ mod \\ b_{n -1}\\end{aligned}\\]  根据辗转相除的规则，我们知道第 0 项中  \\(b = 0, a = 1\\)  ，而我们要求的是第 n 项中的 a 和 b，所以可以通过 a 和 b 的递推公式逐一推导而来。\n如此我们证明了 an 和 bn 的递推关系，下面我们来证明 xn 的递推关系。\n \\[\\begin{aligned} a_0x_0\u0026#43;b_0y_0\u0026amp;=gcd(a_0, b_0)\\\\ a_1x_1\u0026#43;b_1y_1\u0026amp;=gcd(a_1, b_1)\\end{aligned}\\]  由上文证得了：\n \\[\\begin{aligned}\\\\a_{1}\u0026amp;=b_{0} \\\\ b_{1}\u0026amp;=a_{0} \\times 1 - b_{0} \\times (a_{0} | b_{0}) = a_{0}\\ mod \\ b_{0}\\end{aligned}\\]  我们将其带入到第一个式子中：\n \\[b_0x_1\u0026#43;(a_0\\ mod\\ b_0)y_1=gcd(a_1, b_1) \\]   \\[b_0x_1\u0026#43;[a_0\\times 1 - b_0\\times(a_0|b_0)]y_1=gcd(a_1, b_1)\\]  所以可以求得：\n \\[a_0y_1-b_0[x_1-y_1(a_0|b_0)]=gcd(a_1, b_1)\\]  由于辗转相除的推论我们可得：\n \\[gcd(a_1, b_1)=gcd(a_0, b_0)\\]  所以：\n \\[a_0y_1-b_0[x_1-y_1(a_0|b_0)]=a_0x_0\u0026#43;b_0y_0\\]  即：\n \\[\\begin{aligned}x_0\u0026amp;=y_1 \\\\ y_0\u0026amp;=x_1-y_1(a_0|b_0)\\end{aligned}\\]  代码实现扩展欧几里得算法 #  为了实现上述的反向带入原式的过程，我们通过递归递归到最深的一层，将每一层的解带入即可完成最终的求解：\n# python def ex_gcd(a, b): if b == 0: return 1, 0, a else: x, y, r = ex_gcd(b, a % b) x, y = y, (x - (a // b) * y) return x, y, r 但是我们注意到，由于裴蜀定理，我们求解的丢番图方程中，等号右边的常数必须是  \\(k \\times gcd(a, b)\\)  。所以我们的求解其实是：\n \\[ax\u0026#43;by=gcd(a, b)\\times k = c\\]  所以通过扩展 GCD 算法求得的 x0 和 y0 这组解，并不是我们要求的最终解。同样的，我们对其扩大 k 倍就是我们想要对结果：\n \\[x =k·x_0= x_0 \\times \\frac{c}{gcd(a, b)} \\\\y = k·y_0= y_0 \\times \\frac{c}{gcd(a, b)}\\]  小结 #  有了这些知识，你对那道“地狱难度”的头条面试题有没有更多的想法呢？这里有一道 [LeetCode-365] 水壶问题 你可以尝试一下，做完之后想必会对扩展 GCD 算法有更深的理解。\n至于头条面试题，我将在下一篇文继续讲述并代码实现此题的解法。\n"});index.add({'id':12,'href':'/algo/docs/part1/ch01/1-time-complexity/','title':"时间复杂度估算土法",'section':"第一章 刷题技巧",'content':"想必大家都知道很多算法书上面的复杂度计算基础的“第一章节”，长到你不想看。但是不看吧又觉得失去了什么。所以这篇文章就来说说这个复杂度有没有什么通俗易懂的土方法来计算。\n土法一：执行一行约是一次运算 #  我们假设计算机运行一行基础代码，就需要进行一次运算。也就是我们常常说的 O(1)。\n来写一段从 1 累加到 100 的代码：\ns = 0 for i in range(1, 101): s += i print(s) # 5050 如此要循环 100 次，时间复杂度就是   \\(O_{(100)}\\)  。如此，我们改变计算上届，将 100 扩大到 n ，这样便会发现使用循环的方法进行累加是一个时间复杂度为  \\(O_{(n)}\\)  的算法。\n我们将累加算法改成等差数列前 n 项求和来计算：\ns = (1 + 100) * 100 // 2 # 5050 如此，我们将一个  \\(O_{(n)}\\)  的算法优化到了  \\(O_{(1)}\\)  。这种优化无论是对于计算机，还是我们人脑，都可以大幅度的降低运算复杂度。\n为什么说高斯是天才，因为他在小学三年级就发现了这个规律，并将一个  \\(O_{(n)}\\)  的算法优化到了  \\(O_{(1)}\\)  。\n土法二：以经验计算时间 #  以前我在大学的时候参加 ACM 竞赛有这么一个土方法：\n一般的计算机，在处理  \\(10^7\\)  计算的时候需要消耗一秒的时间。可以写一个来验证一下：\nimport datetime tot_time = 0 for t in range(0, 10): st = datetime.datetime.now() sum = 0 for i in range(0, 10000000): sum += i ed = datetime.datetime.now() inv = ed - st tot_time += inv.microseconds / (10 ** 6) print(tot_time / 10) # 0.827902s 我们发现在我的机器上  \\(10^7\\)  数量级的计算在 10 次平均下是 0.827902 秒，接近一秒。\n我们用搜索问题来举例\n 如果我们有一个有序数组 arr ，其中有  \\(10^8\\)  个数字，这时候给出一数字 n ，求在这个数组中是否有这个数 n ，有则返回 true 反之 false 。我们要求在 1000ms 时间内完成。\n 注意最后一句，如果我们采取枚举的方案来解决这个问题，那么我们根据之前的经验来估算，需要  \\(\\frac{10^8}{10^7} \\times 1\\)  也就是 10 秒。\n由于是有序数组，那么我们来计算一下二分查找的复杂度：\n 设数组中有 N 个元素，我们一共需要查询k次，根据这两个条件我们来推导一个 K与N的通项公式（这里面，右边的式子代表在查询完k 次之后，剩余的元素个数）\n  \\[f(1) = \\frac{N}{2} \\\\ f(2) = \\frac{N}{4} \\\\ ... \\\\ f(k) = \\frac{N}{2^k}\\]   由于 k 是查询的次数，也就是计算机一次运算的次数，所以我们只需要反解出 k 的值，也就是我们要求解的时间复杂度。我们假设第 k 次查询是最终态，那么说明此时剩余元素只有 1 个了。那么对于最终态的递推式就可以这样描述：\n  \\[\\frac{N}{2^k}=1\\ \\ \\Rightarrow \\ k=log_{2}{N} \\]  计算完了发展度之后，我们将 N = 10^7 带入，发现 k = 26.57542 。也就是说，只需要 27 次上下的计算机运算，也就是 27 / 10^7 约是 0.0000027 秒，就可以完成查询。\n所以我们如此分析，通过上限时间来推断大致的算法复杂度，获得提示确定了思路，就可以开始解题了。\n土法三：取极限估算复杂度 #   给你一个无序数组 arr ，其中包含 n 个元素 (1 ≤ n ≤ 10^8)，另外给你一个 k (1 ≤ k ≤ n)。让你求出这个数组中的第 k 大数。要求在 1000ms 时间内完成。\n 看完题目第一反映，我们对 arr 数组先做一次降序排序，然后输出 arr[k] 即可。\n那么我们开始使用土法二来估算时间，如果我们进行一次排序，假如是快排，那么首先我们需要一个 O(NlogN) 的复杂度来完成。然后还有一次查询，由于通过数组下标直接访问，需要 O(1) 的一次查询。\n将 n 的范围右边界带入式中，由于我们知道 NlogN \u0026gt; N ，所以根据上面的经验，我们肯定要花费 10s 以上的时间来处理。虽然我们的想法很好，是对数组做一个预处理，然后再进行其他的算法，但实际上，由于预处理的复杂度已经远远的超过了其他计算的复杂度，也就是说我们对于一个方案的复杂度考量，往往都是在一个含操作数 N 的代数式中，当 N 取无穷大时，求每个子式子的等价无穷大，然后取最大值作为整个程序的复杂度。\n拿这题为例：\n \\[f(n)=nlog_{2}n \u0026#43; 1 \\Rightarrow {\\lim_{x \\to \\infty}} \\frac{nlog_{2}n}{1} \\thicksim \\infty \\Rightarrow O_{(nlogn)}\\]  可能这个还不是很明显，我们再举一个例子：\n \\[f(n)=log_{2}n!\u0026#43;nlog_{2}n\u0026#43;n\u0026#43;1\\]  如果我们遇到这种表达式，我们要如何求解呢？我的土法是分成 2 部：\n1. 观察后舍去差距较大的 #  首先，n 和 1 这两个子式显然要比前面两个都小（或者说肯定比 nlogn 要小），我们把它舍去。\n \\[\\Rightarrow f\u0026#39;(n)=log_2n! \u0026#43; nlog_{2}n\\]  2. 不确定式两两使用求极限，判断等价性 #  例如我们得到的 f'(n) 无法判断，那么我就取出这里面两个子式来求等价性：\n \\[\\begin{aligned} \u0026amp;{\\lim_{x \\to \\infty}}\\frac{logn!}{nlogn} \\\\ =\u0026amp;{\\lim_{x \\to \\infty}}\\frac{log((\\sqrt{2\\pi n})\\frac{n^n}{e^n})}{nlogn}\\\\ =\u0026amp;{\\lim_{x \\to \\infty}}\\frac{\\frac{1}{2}log(2\\pi) \u0026#43; \\frac{1}{2}logn \u0026#43; nlogn - nloge}{nlogn} \\\\ =\u0026amp;{\\lim_{x \\to \\infty}}(\\frac{0.5log(2\\pi)}{nlogn}\u0026#43;\\frac{1}{2n}\u0026#43;1-\\frac{1}{ln\\ n})\\\\ =\u0026amp;1 \\end{aligned}\\]  所以我们发现剩下的两个式子是等价无穷大的。我们得到整体的时间复杂度：\n \\[f\u0026#39;(n) \\Rightarrow O(nlog_2n)\\]  所以我们可以总结出来一个规律，子式选最大，就是我们要的时间复杂度。\n总结 #  这篇文章我们讲了：\n 如何结合题目的数据量来估算程序耗时，以及通过复杂度的估算来提示我们要选用什么算法； 耗时和复杂度的关系，大概就是  \\(10^7\\)  为一秒； 取极限来舍去较小的子式，留下的最大子式即可作为整体算法的时间复杂度；  "});index.add({'id':13,'href':'/algo/docs/part2/ch02/2-euclidean/','title':"欧几里得算法",'section':"Docs",'content':"什么是欧几里得算法？欧几里得算法是为了解决 GCD 问题，这里的 GCD 是指 Greatest Common Divisor 即最大公约数，而不是 iOS 中的 Grand Central Dispatch 🤣 。所以这篇分享是关于算法的。\n欧几里得算法（GCD） #  求 GCD 在数论中公认的最常用算法即为欧几里得算法，也就是我们在高中时学到的辗转相除法。\n欧几里得算法的基本原理用一句话就可以说清楚：两个整数的最大公约数等于其中较小的数和两数的差的最大公约数，即   \\(gcd(a, b) = gcd(b, a\\ mod\\ b)\\)  。\n为什么可以这么求呢，这里可以简单证明一下：\n假设  \\(a, b (a \u0026gt; b)\\)  两个数的一个公约数是  \\(t\\)  ，则有\n \\[a=n\\times t \\\\ b=m\\times t\\]  因为  \\(a \u0026gt; b\\)  ，设  \\(a = k × b \u0026#43; r\\)  ，即  \\(r = a\\ mod\\ b\\)  ，将  \\(a,b\\)  代入展开可得：\n \\[a = n \\times t = k \\times m \\times t \u0026#43; r \\\\ \\Rightarrow r = (n - k \\times m) \\times t\\]  由于  \\((n-k \\times m) \\times t\\)  一定是整数，所以 a、b 的公约数 t 也是 r 的约数。所以如果我们递归的求解  \\(a\\ mod\\ b\\)  也就是 a % b ，就可以得到 a、b 的最大公约数 GCD 了。什么时候递归结束呢？当 a % b == 0 的时候，因为在这个过程中，如果 a % b 无法求得正整数 r 时，则无法继续按照上述规律继续拆分。\n# python def gcd(a, b): return a if b == 0 else gcd(b, a % b) // C++ int gcd(int a, int b) { return b == 0 ? a : gcd(b, a % b); } 这里另外提一句，a、b 两数的最大公倍数 LCM(a, b) = a * b / GCD(a, b) 。这里就不证明了，有兴趣的自己谷歌。\n"});index.add({'id':14,'href':'/algo/docs/part3/ch02/1-segment-tree-rmq/','title':"用线段树再看 RMQ 问题",'section':"Docs",'content':" GGTalk 播客\n[28:30] 磊子：国内某特别爱招聘的大厂问过这么一道题：一个数组，要求得任意一个区间段内最大的数是多少。如果大家了解的话，就知道这题其实在考线段树\u0026hellip;.\n 其实 RMQ (Range Minimum/Maximum Query) 问题（又称区间最值问题）之前的文章中也有讲述，在《RMQ 问题》 小节中，通过 ST 的二倍增 + 动态规划的思路，以   \\(O(nlogn)\\)  预处理以及查询  \\(O(1)\\)  复杂度下解决了这个问题。\n也许你会想，在数组中直接遍历一下不就完了了吗，为什么要费这么多事情来做？直接遍历查找一遍也就是  \\(O(n)\\)  的复杂度？是的，其实背景是这样，因为我们需要做  \\(K\\)  次查询，这个  \\(K\\)  的上限很大，你可以理解成这个背景是在海量查询之下。\n所以我们的出发点是通过一种优质的数据结构，将查询复杂度降低成  \\(O(logn)\\)  或者  \\(O(1)\\)  。由于查询次数是强需求，不是算法层面上可以优化的，所以在查询上的效率是我们主要解决的问题。\n为了解决查询问题，这一篇文章我们引入 线段树（Binary Indexed Tree） 来优化 RMQ 问题的查询操作复杂度。\n线段树的概念 #  我们如何理解线段树的定义呢？我们先抛开 RMQ 场景，先引入一个区间求和问题。\n 题目：给你一个数组  \\(A\\)  ，它有  \\(K\\)  次查询，每次查询都给你  \\(a\\)  和  \\(b\\)  两个值，且  \\(a \u0026lt; b \u0026lt; len(A)\\)  ，每次查询输出一个结果，代表  \\(A[a] \u0026#43; A[a \u0026#43; 1] \u0026#43; ... \u0026#43; A[b]\\)  的和。\n 简单描述一下就是给你数组中的两个下标，让你求出这一个区段的和是多少。\n这次不用思考，我直接给出线段树是如何表示的：\n我们将整个数组区段， 通过二分区段的方式，将每一个区段的答案记录在二叉树每一个节点上。 当查询的时候只需要在这个二叉树中对边界做判断，然后拆分成子区间即可。\n所以你应该可以理解，为什么它要叫“线段树”了吧，答案就是它会将整个区段抽象成一个大“线段”，然后根据表示的范围，二分划分成子“线段”。\n如此我们给出线段树的定义： 线段树是一棵二叉树，线段树上每个结点对应的是序列的一段区间，每一个叶子结点对应的是序列的一个元素。树上的每个节点都维护一个区间，根维护的是整个区间，每个节点维护的是父亲的区间二等分后的其中一个子区间。 当有  \\(a\\)  个元素时，对区间的操作可以在  \\(O(logn)\\)  复杂度时间内完成。另外，从二叉树结构上，可以看出线段树是一棵完美二叉树（Perfect Binary Tree），即所有叶子的深度都相同，并且每个节点要么是叶子，要么有 2 个子树。\n不同场景下线段树的功能 #  根据节点维护的数据含义不同，线段树可以提供不同的功能来满足各种各样的区间场景。下面我们先以上例中讲述的区间和为例，进而引出 RMQ 的使用场景。\n求区间和 #  基础数据结构描述 #  任何数据结构都要从它的构造开始说起。以往我们想当然的认为，树状结构都应该以链式数据来存储。但其实二叉树使用数组描述可能更加简单明了。由于线段树也是二叉树，所以以下所有的表示方式我都使用数组来描述。\n另外，假设我们的节点是  \\(N\\)  个，根据线段树结构的性质，我们会把这  \\(N\\)  个点当做叶子节点来看待。由于线段树是一棵满二叉树，假设它有  \\(H\\)  层，第  \\(H\\)  层节点数是  \\(2^{H - 1}\\)  个，一共  \\( 2^H - 1\\)  个节点。假设共  \\(S\\)  个节点，我们来推导一下：\n \\[ S = 2^H-1=2^{H-1}2-1=2N-1\\]  那么只要让这个数组的大小开成节点数的两倍，就可以装满全部节点？其实是错误的！ 我们先暂且记住，正确的答案应该是  \\(4N\\)  ，具体原因可以查看下一篇《线段树实战要点》的 空间退化问题。\n所以将线段树使用以下方式来声明。\nconst int maxn = 1e4 + 7; int tree[maxn \u0026lt;\u0026lt; 2]; 一个知识基础：使用数组 tree[N] 来描述二叉树，对于节点 tree[i] ，它的左右孩子节点分别是 tree[2 * i] 和 tree[2 * i + 1]。在代码中为了稍微稍微做一些加速，所以我用 tree[i \u0026lt;\u0026lt; 2] 和 tree[i \u0026lt;\u0026lt; 2 | 1] 来表示。\nBuild 及 Push Up 操作 #  我们需要构造（Build）一棵线段树，与之同时我们还要考虑这棵线段树的 Push Up 操作。这个 Push Up 操作可以理解成是一种向上更新的概念。\nvoid push_up(int rt) { tree[rt] = tree[rt \u0026lt;\u0026lt; 1] + tree[rt \u0026lt;\u0026lt; 1 | 1]; } 通过代码可以看出，其实我们是使用下方的两个孩子节点，来更新其共同的父亲结点。从二叉树的角度来看，这个操作由于是向上方来更新维护的数据，所以我们称之为 Push Up 操作 。\n具体的 Push Up 操作是为了实现什么效果呢？看这张动图你就懂了：\n有了 Push Up 操作后，我们就可以自底向上来构建这棵二叉树了。由于我们知道根节点是 tree[1] ，而所有需要 Push Up 操作的元素都是最底部的叶子结点，所以在构造的时候需要先访问到最底部，递归调用 Push Up 向上更新即可。\n/*** * * @param l 当前节点描述范围的左边界 * @param r 当前节点描述范围的右边界 * @param rt 代表下标，tree[rt] 代表当前节点 */ void build(int l, int r, int rt) { if (l == r) { tree[rt] = num[cur ++]; return ; } int m = (l + r) \u0026gt;\u0026gt; 1; build(l, m, rt \u0026lt;\u0026lt; 1); build(m + 1, r, rt \u0026lt;\u0026lt; 1 | 1); // 这里递归到叶子执行一次向上更新  // 保证每一层都在上一层有数值之后执行  push_up(rt); } 从这里可以看的出，其实我们构造一棵线段树，就需要执行多达  \\(O(nlogn)\\)  的复杂度。但是考虑到是海量查询的场景，而构造是一次性的（因为线段树是支持更新操作的，这个在本公众号后续篇幅将会讲到），所以从特殊场景下来看这个优化，是很合理的。\n如此，我们完成了一棵线段树的创建。\n 瓜自己的归纳总结：线段树其实最重要的是“两操作，一思想”。两操作中，包括 Push Up 和 Push Down 两个操作，一个思想是 Lazy 延迟更新思想。Lazy 延迟更新其实在并查集中我们已经体会到了，在线段树中该如何使用了？这个需要等到线段树的区间更新操作才会讲到。Lazy 延迟更新和 Push Down 操作是紧密相连的。\n Query 查询操作实现区间和 #  重头戏在这里，也是我们需要核心解决的问题 - 我们要如何做区间查询？\n我们都知道，如果给你一个排序二叉树，当我查询是否有某个元素的时候，从根节点开始逐一比较节点大小，从而决策是向左走还是向右走就可以了。\n而这里要面对的是一个线段树，线段树每一个节点代表的是一个区间。自然而然，我们只要弄清楚当前结点表示的是哪个区间，从而比较查询区间的边界值，就可以知道在下一层要往哪里走了。\n那如果遇到卡区间的情况怎么办？就是，如果我查询  \\([1, 6]\\)  这个区间，而当前结点是根节点  \\([1, 8]\\)  ，左区间是  \\([1, 4]\\)  右区间是  \\([5, 8]\\)  这种情况，没有一个恰好能满足我们查询区域的区间范围。这时候我们只要把  \\([1, 8]\\)  划分成  \\([1, 4]\\)  和  \\([5, 6]\\)  分头查找就可以了。我们用树的遍历思想，其实就是两次递归可以了。\n/*** * * @param L 待查询区间左边界 * @param R 待查询区间右边界 * @param l 当前节点描述范围的左边界 * @param r 当前节点描述范围的右边界 * @param rt 代表下标，tree[rt] 代表当前节点 */ int query(int L, int R, int l, int r, int rt) { if (L \u0026lt;= l \u0026amp;\u0026amp; r \u0026lt;= R) { return tree[rt]; } int m = (l + r) \u0026gt;\u0026gt; 1; int ret = 0; if (L \u0026lt;= m) ret += query(L, R, l, m, rt \u0026lt;\u0026lt; 1); if (R \u0026gt; m) ret += query(L, R, m + 1, r, rt \u0026lt;\u0026lt; 1 | 1); return ret; } 单点更新操作 #  线段树的优势还在于我们可以对某一个节点做更新操作。这一点是 ST 算法不具备的能力。其实单点更新操作与 build 方法的想法十分雷同，我们只要递归到叶子节点，将更新值修改掉，之后逐渐向上执行 push_up 更新，其实就完成了新状态的维护。\n/*** * * @param p 待更新的下标，指的在 num 中的下标 * @param replace 待替换的值 * @param l 当前节点描述范围的左边界 * @param r 当前节点描述范围的右边界 * @param rt 代表下标，tree[rt] 代表当前节点 */ void update(int p, int replace, int l, int r, int rt) { if (l == r) { tree[rt] = replace; return ; } int m = (l + r) \u0026gt;\u0026gt; 1; if (p \u0026lt;= m) update(p, replace, l, m, rt \u0026lt;\u0026lt; 1); else update(p, replace, m + 1, r, rt \u0026lt;\u0026lt; 1 | 1); push_up(rt); } 单元测试 #  我们将以上的代码整合一下，自己模拟做有个单元测试。来验证这个支持单点修改的区间和查询场景。\n#include \u0026lt;iostream\u0026gt;#include \u0026lt;vector\u0026gt;using namespace std; const int maxn = 1e4 + 7; vector\u0026lt;int\u0026gt; num(maxn); int cur = 0; int tree[maxn \u0026lt;\u0026lt; 2]; void push_up(int rt) { tree[rt] = tree[rt \u0026lt;\u0026lt; 1] + tree[rt \u0026lt;\u0026lt; 1 | 1]; } /*** * * @param l 当前节点描述范围的左边界 * @param r 当前节点描述范围的右边界 * @param rt 代表下标，tree[rt] 代表当前节点 */ void build(int l, int r, int rt) { if (l == r) { tree[rt] = num[cur ++]; return ; } int m = (l + r) \u0026gt;\u0026gt; 1; build(l, m, rt \u0026lt;\u0026lt; 1); build(m + 1, r, rt \u0026lt;\u0026lt; 1 | 1); push_up(rt); } /*** * * @param L 待查询区间左边界 * @param R 待查询区间右边界 * @param l 当前节点描述范围的左边界 * @param r 当前节点描述范围的右边界 * @param rt 代表下标，tree[rt] 代表当前节点 */ int query(int L, int R, int l, int r, int rt) { if (L \u0026lt;= l \u0026amp;\u0026amp; r \u0026lt;= R) { return tree[rt]; } int m = (l + r) \u0026gt;\u0026gt; 1; int ret = 0; if (L \u0026lt;= m) ret += query(L, R, l, m, rt \u0026lt;\u0026lt; 1); if (R \u0026gt; m) ret += query(L, R, m + 1, r, rt \u0026lt;\u0026lt; 1 | 1); return ret; } /*** * * @param p 待更新的下标，指的在 num 中的下标 * @param replace 待替换的值 * @param l 当前节点描述范围的左边界 * @param r 当前节点描述范围的右边界 * @param rt 代表下标，tree[rt] 代表当前节点 */ void update(int p, int replace, int l, int r, int rt) { if (l == r) { tree[rt] = replace; return ; } int m = (l + r) \u0026gt;\u0026gt; 1; if (p \u0026lt;= m) update(p, replace, l, m, rt \u0026lt;\u0026lt; 1); else update(p, replace, m + 1, r, rt \u0026lt;\u0026lt; 1 | 1); push_up(rt); } int main() { // [1, 8, 3, 4, 7, 1, 6, 2]  num = vector\u0026lt;int\u0026gt;({1, 8, 3, 4, 7, 1, 6, 2}); int n = num.size(); build(1, n, 1); cout \u0026lt;\u0026lt; query(1, 3, 1, n, 1) \u0026lt;\u0026lt; endl; // 1 + 8 + 3 = 12  cout \u0026lt;\u0026lt; query(3, 8, 1, n, 1) \u0026lt;\u0026lt; endl; // 3 + 4 + 7 + 1 + 6 + 2 = 23  update(3, 10, 1, n, 1); // [1, 8, 10, 4, 7, 1, 6, 2]  cout \u0026lt;\u0026lt; query(1, 3, 1, n, 1) \u0026lt;\u0026lt; endl; // 1 + 8 + 10 = 19 } /* * 输出 * 12 * 23 * 19 * */ 完成测试，全部符合预期结果。😁\nRMQ 问题 #  我们再来看 RMQ 问题。上面我们通过 Push Up 方法中，父节点等于两个孩子结点之和来构造的区间和树。通过这个思路来想，如果我们修改 Push Up 操作，将父亲节点等于两个孩子节点的最大值，是不是就完成了区间最大线段树？\nvoid push_up(int rt) { tree[rt] = max(tree[rt \u0026lt;\u0026lt; 1], tree[rt \u0026lt;\u0026lt; 1 | 1]); } 通过动画来表示，看起来很有道理！要实现 RMQ 问题的查询操作 query ，可能还要使用类似的思路做修改。这个修改就交给聪明的你了！也算是这篇文章给你出的一道思考题。\nPush Up 操作的理解 #  为什么在线段树中 Push Up 操作如此重要？push-up 在英文中是俯卧撑的意思，由于线段树的叶子节点是对应我们实际数组中的每个元素，根据叶子节点，我们才能向上计算父亲节点的数值，通过子结点“撑起”父节点，意在于此。另外，由于线段树最关键的地方就在于父亲节点和孩子节点之间的关系是什么（其实有规律的二叉树都是这样），而 Push Up 操作却恰恰是用来描述这个关系的，所以 Push Up 是线段树最重要的操作之一。\n线段树只所以区别于其他二叉树，原因是在于描述区间。二叉树往往是通过父亲来确定下一个孩子的位置（例如排序二叉树，插入节点向下填充），而线段树是通过孩子节点来确定父节点。从宏观上看，通常二叉树是向下更新，而线段树是向上更新。Push Up 是决定向上更新的策略是如何的，其重要性不言而喻了。\n复杂度分析 #  无论是区间求和，还是 RMQ，通过线段树的数据结构来描述数据，实现了构造  \\(O(4n)\\)  ，查询  \\(O(klogn)\\)  ( \\(k\\)  代表可能出现的跨区域多路径)，单点更新  \\(O(logn)\\)  。对比与我们用数组来描述原始数据，构造  \\(O(N)\\)  ，查询  \\(O(N)\\)  ，更新  \\(O(1)\\)  来说，在多查询的场景下，会有很大幅度的优化。\n总结 #  通过 RMQ 线段树通过区间和线段树的简单转换，其实我们已经知道了，线段树能解决的问题不仅仅是这两个场景。其实只要是区间查询、区间操作问题中，并且区间内有确定运算结果场景下，都可以通过线段树来优化查询、更新的复杂度，例如：区间求 GCD（最大公约数）、区间求异或结果等等。\n另外，对于线段树的探究远不止于此。后续还会有向下更新、区间更新这两个操作的加入，才能更大的发挥线段树的威力。这些都会在后续的文章中逐一分析！\n"});index.add({'id':15,'href':'/algo/docs/part2/ch01/3-matrix-quick-pow/','title':"矩阵快速幂",'section':"Docs",'content':"回顾 #  在上一篇文章中，我们对快速幂算法进行了如下的分析：\nint qpow(int x, int n, int m) { int res = 1; while (n) { if (n \u0026amp; 1) res = res * x % m; x = x * x % m; n \u0026gt;\u0026gt;= 1; } return res; } int main() { cout \u0026lt;\u0026lt; qpow(10, 3, 997) \u0026lt;\u0026lt; endl; // 3  cout \u0026lt;\u0026lt; qpow(10, 2, 997) \u0026lt;\u0026lt; endl; // 100  return 0; }  我们的快速幂算法其实并没有真正的优化乘法效率，而是通过二进制拆分，从而优化了乘法运算的次数，具体的表现就是 x *= x 来扩大乘子的基数； 在计算 res 的时候，res *= x 仍旧是一个累乘的过程，唯一的变化就是 x 在由于 x *= x 逐渐变化。这两个式子结合起来，其实就是 res 不断的去累乘多个 x 。  其中的关键就是快速幂其实没有真正优化乘法的效率，而是优化了乘法运算的次数。\n我们换一个角度来想，如果有这么一种东西，它也支持乘法和幂运算，同样也拥有像数的乘法一样的规律，是不是也可以进行快速幂的优化？\n斐波那契，万物之源 #  看到这个小标题是不是一脸蒙圈？\n为什么快速幂会与斐波那契有关？听我来慢慢道来。\n我们都知道斐波那契的递推公式：\n  \\[Fib(n)=Fib(n - 1)\u0026#43;Fib(n-2)\\]  所以 Fib(n) 和 Fib(n - 1) 是存在一定关系的。我们通过构造一个多项式，来找出关系：\n \\[\\begin{aligned} \u0026amp; f(n)\u0026amp;=f(n-1)\u0026amp;\u0026#43;f(n-2) \\\\ \u0026amp; f(n - 1)\u0026amp;= f(n-1) \u0026amp;\\end{aligned}\\]  我们讲 Fib(n - 1) 也写入多项式方程中，目的是为了凑足一个多项式，从而将右式中只含有 f(n - 1) 和 f(n - 2) 。\n我们把右边的 f(n - 1) 及 f(n - 2) 看做 x1 和 x2 ，左边的 f(n) 和 f(n - 1) 看做 y1 和 y2 ，得到下式：\n \\[\\begin{aligned}\u0026amp; y_1=\u0026amp;x_1\u0026amp;\u0026#43;x_2 \\\\ \u0026amp; y_2= \u0026amp;x_1\u0026amp;\\end{aligned} \\]  看到这个你是否想起了有一门叫做《线性代数》的课程，当遇到一个齐次线性方程组时，我们可以通过 系数矩阵 * N 维向量 来表示，即：\n \\[A·X=B\\]  这里我们将上式通过矩阵方程来表示：\n \\[\\begin{bmatrix}y_1\\\\y_2\\end{bmatrix}=\\begin{bmatrix}1\u0026amp;1\\\\ 1\u0026amp;0\\end{bmatrix}\\begin{bmatrix}x_1\\\\x_2\\end{bmatrix}\\]   \\[\\begin{bmatrix}f(n)\\\\f(n-1)\\end{bmatrix}=\\begin{bmatrix}1\u0026amp;1\\\\ 1\u0026amp;0\\end{bmatrix}\\begin{bmatrix}f(n-1)\\\\f(n-2)\\end{bmatrix}\\]  设 \\(\\begin{bmatrix}f(n)\\\\f(n-1)\\end{bmatrix}\\)  为 \\(F(n)\\)  ，则 \\( F(n)=\\begin{bmatrix}1\u0026amp;1\\\\ 1\u0026amp;0\\end{bmatrix}·F(n-1)\\)  这里我们把矩阵可以当成一个常数来看，其实这就是一个“等比数列”的地推公式，其“公比”就是那个零一矩阵！\n所以我们可以得到：\n \\[\\begin{bmatrix}f(n)\\\\f(n-1)\\end{bmatrix}=\\begin{bmatrix}1\u0026amp;1\\\\ 1\u0026amp;0\\end{bmatrix}^{n-1}\\begin{bmatrix}f(1)\\\\f(0)\\end{bmatrix}\\]  所以最终，我们将其转换成了一个求解矩阵幂运算的通项公式。\n矩阵乘法实现 #  以下是矩阵乘法的规律：\n \\[A = \\begin{bmatrix}a_{1, 1} \u0026amp; a_{1, 2} \u0026amp; a_{1,3}\\\\a_{2, 1} \u0026amp; a_{2, 2} \u0026amp; a_{2,3}\\end{bmatrix}\\]   \\[B = \\begin{bmatrix}b_{1, 1} \u0026amp; b_{1, 2} \\\\b_{2, 1} \u0026amp; b_{2, 2} \\\\ b_{3, 1} \u0026amp; b_{3, 2}\\end{bmatrix}\\]   \\(C=A·B=\\begin{bmatrix}a_{1,1}b_{1, 1}\u0026#43;a_{1, 2}b{_{2, 1}\u0026#43;a_{1,3}b_{3, 1}} \u0026amp; a_{1,1}b_{1, 2}\u0026#43;a_{1, 2}b{_{2, 2}\u0026#43;a_{1,3}b_{3, 2}} \\\\a_{2,1}b_{1, 1}\u0026#43;a_{2, 2}b{_{2, 1}\u0026#43;a_{2,3}b_{3, 1}} \u0026amp; a_{2,1}b_{1, 2}\u0026#43;a_{2, 2}b{_{2, 2}\u0026#43;a_{2,3}b_{3, 2}} \\end{bmatrix}\\)  根据 n * m 和 m * n 矩阵的规律，我们来写一个矩阵乘法的实现：\n#define N 2  struct matrix { int m[N][N]; matrix() { memset(m, 0, sizeof(m)); } void prt(); }; matrix operator * (const matrix a, const matrix b) { matrix ans; for (int i = 0; i \u0026lt; N; ++ i) { for (int j = 0; j \u0026lt; N; ++ j) { for(int k = 0; k \u0026lt; N; ++ k) { ans.m[i][j] += a.m[i][k] * b.m[k][j]; } } } return ans; } // 打印测试代码 void matrix::prt() { for (int i = 0; i \u0026lt; N; ++ i) { for (int j = 0; j \u0026lt; N; ++ j) { cout \u0026lt;\u0026lt; this -\u0026gt; m[i][j] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } } 改写快速幂类型 #  既然我们已经对矩阵的 matrix 的结构体做了乘法符号重载，那么我们的快速幂算法实现直接对类型做修改即可：\nmatrix qpow(matrix x, int n) { matrix res; for (int i = 0; i \u0026lt; N; ++ i) { res.m[i][i] = 1; } while (n) { if (n \u0026amp; 1) res = res * x; x = x * x; n \u0026gt;\u0026gt;= 1; } return res; } 根据 Fib 数列封装 #  上文我们推导出了斐波那契的矩阵通项公式：\n \\[\\begin{bmatrix}f(n)\\\\f(n-1)\\end{bmatrix}=\\begin{bmatrix}1\u0026amp;1\\\\ 1\u0026amp;0\\end{bmatrix}^{n-1}\\begin{bmatrix}f(1)\\\\f(0)\\end{bmatrix}\\]  然后我们将 f(1) = 1 和 f(0) = 0 带入，形成 base 矩阵。在对左边的零一矩阵做 n - 1 的幂运算，乘以 base 矩阵，返回结果矩阵的 res[0][0] 就是我们要求的 Fib[n]。\nint fib(int n) { matrix a; a.m[0][0] = a.m[1][0] = a.m[0][1] = 1; matrix base; base.m[0][0] = 1; matrix ans = qpow(a, n - 1); ans = ans * base; return ans.m[0][0]; } 简单的单元测试 #  我们对矩阵快速幂求解斐波那契数列来做一个简单的单元测试，来查看是否满足斐波那契数列的规律。\n#include \u0026lt;iostream\u0026gt; using namespace std; #define N 2  struct matrix { int m[N][N]; matrix() { memset(m, 0, sizeof(m)); } void prt(); }; void matrix::prt() { for (int i = 0; i \u0026lt; N; ++ i) { for (int j = 0; j \u0026lt; N; ++ j) { cout \u0026lt;\u0026lt; this -\u0026gt; m[i][j] \u0026lt;\u0026lt; \u0026#34; \u0026#34;; } cout \u0026lt;\u0026lt; endl; } } matrix operator * (const matrix a, const matrix b) { matrix ans; for (int i = 0; i \u0026lt; N; ++ i) { for (int j = 0; j \u0026lt; N; ++ j) { for(int k = 0; k \u0026lt; N; ++ k) { ans.m[i][j] += a.m[i][k] * b.m[k][j]; } } } return ans; } matrix qpow(matrix x, int n) { matrix res; for (int i = 0; i \u0026lt; N; ++ i) { res.m[i][i] = 1; } while (n) { if (n \u0026amp; 1) res = res * x; x = x * x; n \u0026gt;\u0026gt;= 1; } return res; } int fib(int n) { matrix a; a.m[0][0] = a.m[1][0] = a.m[0][1] = 1; matrix base; base.m[0][0] = 1; matrix ans = qpow(a, n - 1); ans = ans * base; return ans.m[0][0]; } int main() { cout \u0026lt;\u0026lt; fib(1) \u0026lt;\u0026lt; endl; // 1  cout \u0026lt;\u0026lt; fib(2) \u0026lt;\u0026lt; endl; // 1  cout \u0026lt;\u0026lt; fib(3) \u0026lt;\u0026lt; endl; // 2  cout \u0026lt;\u0026lt; fib(4) \u0026lt;\u0026lt; endl; // 3  cout \u0026lt;\u0026lt; fib(5) \u0026lt;\u0026lt; endl; // 5  cout \u0026lt;\u0026lt; fib(6) \u0026lt;\u0026lt; endl; // 8  cout \u0026lt;\u0026lt; fib(7) \u0026lt;\u0026lt; endl; // 13 } 结尾 #  好了这篇文章你已经学会了矩阵快速幂。可能你会觉得很少有场景会使用到这个。这个我说一句实话是这样，只有在一些特殊的递推公式中才能通过矩阵相乘的方式找到通项公式。后面我会总结一下有哪些常见的递推公式可以使用矩阵快速幂来求得通项公式。\n"});index.add({'id':16,'href':'/algo/docs/part2/ch01/4-matrix-quick-pow-analysis/','title':"矩阵的递推关系分析",'section':"Docs",'content':"这篇文章可能会有一些难度，但是所有的预备基础都在前三篇文章中：\n 快速幂 快速幂取模 矩阵快速幂  引子 #  数字是我们在编程中最常接触的元数据。无论是在业务还是刷题，多半部分都是数字的运算，其次是字符串，再次是布尔。\n虽然矩阵也是由数字构成的，但是矩阵往往是描述一个多元方程组的元数据。在业务中很少接触方程的运算，所以自然而然的《线性代数》这门重要但又不重要的学科在工作后说忘就忘。\n所以，这篇文章可能对于你工作甚至是面试都不一定有直接的收益，如果考虑业务能力和面试 ROI，也就不需要再浪费时间阅读。\n斐波那契的矩阵快速幂归纳 #  通过之前的文章，我们已经推出了斐波那契数列通过矩阵来表示的递推公式：\n  \\[\\begin{bmatrix}f(n)\\\\f(n-1)\\end{bmatrix}=\\begin{bmatrix}1\u0026amp;1\\\\ 1\u0026amp;0\\end{bmatrix}\\begin{bmatrix}f(n-1)\\\\f(n-2)\\end{bmatrix}\\]  再来分析一下我们将表达式  \\(f(n) = f(n - 1) \u0026#43; f(n - 2)\\)  转化成矩阵形式的递推公式到底目的是什么？为什么只要这么做，就可以带来优化算法时间复杂度的收益？\n从这三个点来思考：\n 关系变量减少：原来是  \\(f(n) = f(n - 1) \u0026#43; f(n - 2)\\)  ，通过矩阵表示后，降为  \\(A(n - 1)·C = A(n)\\)  。 恰好通过矩阵形式表示后变成了一个等比数列的形式，这样就可以求出通向公式。而通向公式又是一个幂指数的运算，所以我们联想到了快速幂算法。  \\(N · N\\)  方阵的矩阵乘法，遵循结合律。  归纳问题 #  思考点 3 是矩阵的规律，这个我们就不再细究。但是思考点 1 和 2，可以为我们延伸出以下的几种场景：\n增加系数 #  重点在于如果我们遇到一个表达式  \\(f(x)\\)  ，只要我们能得到它的递推公式，将其转换成  \\(A(n - 1)·C = A(n)\\)  的形式其实就可以沿用斐波那契数列矩阵快速幂的整体思路拉求解。既然这样，我们就再次从斐波那契数列入手，先对  \\(f(n - 1)\\)  和  \\(f(n - 2)\\)  加系数：\n \\[f(n)=a\\ f(n-1)\u0026#43;b\\ f(n-2)\\]  使用与推导斐波那契矩阵表达式相同的方式，来对上式进行推导：\n \\[\\begin{cases}\\begin{aligned}\u0026amp; f(n)=\u0026amp;af(n-1)\u0026amp;\u0026#43;bf(n-2) \\\\ \u0026amp; f(n - 1)= \u0026amp;f(n-1)\u0026amp;\\end{aligned} \\end{cases}\\]   \\[\\begin{bmatrix}f(n)\\\\f(n-1)\\end{bmatrix}=\\begin{bmatrix}a\u0026amp;b\\\\ 1\u0026amp;0\\end{bmatrix}\\begin{bmatrix}f(n-1)\\\\f(n-2)\\end{bmatrix}\\]  这里给出一道对应的训练习题：HDU 1757 - A Simple Math Problem。\n增加常数 #  在增加系数的基础上，我们可以继续的增加常数，例如下式：\n \\[f(n)=a\\ f(n-1)\u0026#43;b\\ f(n-2) \u0026#43; c\\]  根据上面的推导经验，由于我们的右边要构造成  \\(A(n - 1)·C\\)  的结构，为了保证递推关系，在这种情况下可以进行扩维操作。\n \\[\\begin{cases}\\begin{aligned}\u0026amp; f(n)\u0026amp;=\u0026amp;af(n-1)\u0026amp;\u0026#43;\u0026amp;bf(n-2)\u0026amp;\u0026#43;\u0026amp;c \\\\ \u0026amp; f(n - 1)\u0026amp;=\u0026amp;\\ f(n-1) \\\\ \u0026amp;c\u0026amp;=\u0026amp;\u0026amp;\u0026amp;\u0026amp;c\\end{aligned} \\end{cases}\\]   \\[\\begin{bmatrix}f(n)\\\\f(n-1)\\\\c\\end{bmatrix}=\\begin{bmatrix}a\u0026amp;b\u0026amp;1\\\\ 1\u0026amp;0\u0026amp;0 \\\\ 0\u0026amp;0\u0026amp;1\\end{bmatrix}\\begin{bmatrix}f(n-1)\\\\f(n-2)\\\\c\\end{bmatrix}\\]  由此，对于增加常数或者增加齐次的项数这种情况，可以使用上述方法，通过扩维来扩展矩阵对多项式的表达。\n指数变量的处理 #  其实很多情况下，并不是单纯的  \\(f(n)\\)  的单一函数，也有可能含有  \\(g(n)\\)  的形式存在于代数项式中。如果我们想用矩阵来表示递推关系式，必须要满足  \\(g(n)\\)  在乘积的情况下，表现出自变量 n 自增的情况。符合这种条件的就是指数函数。\n例如下式：\n \\[f(n)=a\\ c^{n}\u0026#43;b\\ f(n-1) \u0026#43; d\\]  我们将指数函数用  \\(g(n)\\)  来表示，并且可以发现其中有这么一个规律：\n \\[g(n)=c^n\\]  $$g(n)=g(n-1) \\times g(1) = c^{n-1}c$$\n这里  \\(g(n)\\)  的规律，其实就是我上面所说的对函数的乘积表现为自变量的加和。\n所以这里可以如此构造  \\(f(n)\\)  的矩阵递推式：\n \\[\\begin{bmatrix}f(n)\\\\c^n\\\\d\\end{bmatrix}=\\begin{bmatrix}b\u0026amp;ac\u0026amp;1\\\\ 0\u0026amp;c\u0026amp;0 \\\\ 0\u0026amp;0\u0026amp;1\\end{bmatrix}\\begin{bmatrix}f(n-1)\\\\c^{n-1}\\\\d\\end{bmatrix}\\]  如此，含有指数函数  \\(g(n)\\)  为项式的情况我们也可以通过矩阵快速幂来求解。\n嵌套矩阵 #  通过上面的总结，其实我们解决的核心问题就是将递推公式转化成矩阵形式即可。继续来发散性思维，如果递推公式中已经有矩阵，那么是不是也可以使用相同的关系式思路来转化问题呢？\n答案肯定是可以的。这里给出一道例题 POJ-3233 Matrix Power Series。\n题目描述了如果存在下列等式：\n \\[S_k=A\u0026#43;A^1\u0026#43;A^2\u0026#43;...\u0026#43;A^k=\\sum^{k}_{i=1}A^i\\]  其实根据这种求和式子我们可以立马推出：\n \\[S_k=A·S_{k-1} \u0026#43; A\\]  泛型这是一个 k 和 k - 1 的递推公式，另外有一个常数项。根据前文的一些推导经验，我们来构造多项式和矩阵表示：\n \\[\\begin{cases}\\begin{aligned}\u0026amp; S(n)=\u0026amp;A·S(n-1)\u0026amp;\u0026#43;\u0026amp;A \\\\ \u0026amp; A= \u0026amp;\u0026amp;\u0026amp;A\u0026amp;\\end{aligned} \\end{cases}\\]  由于 S(n) 和 A 都是矩阵，所以前文在构造矩阵的时候，其中的单位 1 都要改成单位矩阵 E。\n \\[\\begin{bmatrix}S(n)\\\\A\\end{bmatrix}=\\begin{bmatrix}A\u0026amp;E\\\\ 0\u0026amp;E\\end{bmatrix}\\begin{bmatrix}S(n-1)\\\\A\\end{bmatrix}\\]  如此，矩阵的嵌套问题也就解决了。\n总结与延伸学习 #  我们专题性地研究了快速幂算法，直至现在应该将在计算机领域中所有场景的快速幂问题全部覆盖到了。但其中让你受益最大的，仍旧是在数字领域中的快速幂取模算法，所以我个人的建议是矩阵场景下无需更多的关注。\n这里给大家带来两个延伸学习：\n 矩阵快速幂中其实还有一个瓶颈你可以继续深入的去研究，那就是矩阵乘法的效率优化。在之前的实现中，所有的矩阵乘法都是通过  \\(O(n^3)\\)  的方式来实现的，这里给你抛出一个有意思的矩阵乘法算法 - Strassen algorithm，它可以将矩阵乘法的时间复杂度优化到  \\(O(n^{log7})\\)  ，其核心思想是分治。 在某些场景下的二项式展开也可以利用矩阵来描述递推式，这里给你延伸一下帕斯卡恒等式，在某些二项式展开的情况下，可以快速进行递推，减少运算次数。对应习题是 HDU-2855。  以上就是矩阵快速幂的所有进阶内容了，多谢大家支持。\n"});index.add({'id':18,'href':'/algo/docs/part3/ch02/3-segment-tree-range/','title':"线段树区间更新操作",'section':"Docs",'content':"在之前的文章中，我们已经学习了如何使用线段树来做一些常规的区间操作：如何建树、单点更新、区间查询。这些操作通过线段树这种数据结构的特点，将单点更新和区间查询的复杂度都统一到   \\(O(logn)\\)  ，在海量查询场景下的开销也降低了很多。\n那么关于线段树的讨论就到此为止了吗？其实并不是。我们学到的还只是冰山一角。这篇文章，我们来讨论一下如何通过线段树来实现区间更新。区间更新的操作在这里指的是对某一个范围的数进行增加或减少同一个常数的操作。例如数组 [2, 3, 4, 5, 6] ，对其下标 [0, 2] 进行区间更新都增加 10 ，则数组会变成 [12, 13, 14, 5, 6] 。\n以下对于线段树的讨论全部以区间和场景为准。\n单点更新遍历 #  当我们讨论区间更新的时候，肯定已经有读者开始思考：只要我们遍历一下区间的每一个值，执行单点更新不就可以了？\n从结果上来看，这么做完全可以。从复杂度上来看，以  \\(O(nlogn)\\)  复杂度执行一次长度为  \\(n\\)  的区间更新。\n我们回过头来看我们引出线段树目的是什么？为了实现常数复杂度时间构造和对数复杂度的操作。那么，我们有没有方式将区间更新操作通过对数复杂度  \\(O(logn)\\)  时间来更新一个区间的数值呢？\n考虑查询时候的行为 #  上文介绍的 query 操作总结成动图如下（假设我们有下标 [1, 8] 8 个元素构成的区间和线段树，此时我们要查询 [1, 6] 这个区间）：\n我们可以发现，其实在每次查询的时候，是不断对当前层级所表示的区间进行二分分治，直到最后每个分块的并集即为待查询区间。\n另外线段树还有一个特点：由于我们引入的 push_up 操作，这就会让线段树有这么一个特点：父亲结点是包括子结点的状态。这是一个什么意思呢？拿区间和为例，push_up 是通过子结点数值求和来构造父结点，即：\ntree[rt] = tree[rt * 2] + tree[rt * 2 + 1] 由于这个核心操作，我们发现我们描述的线段树是一种下级扩展上级的结构。当查询的时候，如果查询的节点所描述的区间符合要求，则会被计算到结果中。\n要确定一个目标，我们的节点更新其实是为了查询到最新的结果。\n所以有这么一个思路， 对所有查询范围中最小粒度的节点进行更新，从而就能让所有的查询操作返回最新的情况。什么是范围中最小粒度的节点呢？其实就是要满足两个特点：\n 在查询范围中； 尽量在线段树的上层。  增量记录 #  根据查询自上到下的特点，我们来维护一个增量数组，这个增量数组代表对应的节点待更新的增量。假设我们对上面动图上的线段树进行一个区间更新的操作，将 [3, 6] 这个区间上的所有数字增加 4 。此时我们的增量数组如图所示：\n为什么要单独用一个属性来记录增量？因为我们上面的图片发现我们需要查的 [1, 6] 这个区间，其最小颗粒度的查询节点是 [1, 4] 和 [5, 6] 这两个节点，所以我们将增量向下更新到这两个节点，就能保证我们查询 [1, 6] 这个区间的正确性。\n于是，通过这个思路我们来思考，当我们需要对一个区间进行批量增减操作的时候，我们只要向下更新到我们所有查询操作的最小粒度即可，而不用完全对整个线段树进行更新，是不是就完成了复杂度的优化！\n这就是  \\(O(logN)\\)  级别的批量更新思路，沿着这个思路我们继续来看 Push Down 操作。\nPush Down 操作 #  所谓 Push Down 操作，与我们第一篇文中所讲述的 Push Up 操作相反，Push Down 也就是向下更新的意思。因为我们要引入这个增量的记录数组，所以我们需要 Push Down 操作。\nvoid push_down(int rt, int m) { // 如果增量数组有值，则我们将其向下更新  // 此时的增量数组已经被放置在了最小颗粒度查询节点  // 向下更新是为了更新到 sum 数组  if (add[rt]) { // 先向下传递更新  add[rt \u0026lt;\u0026lt; 1] += add[rt]; add[rt \u0026lt;\u0026lt; 1 | 1] += add[rt]; // 由于描述的是一个区间的批量更新，则这个区间要增加 detal * cnt  sum[rt \u0026lt;\u0026lt; 1] += add[rt] * (m - (m \u0026gt;\u0026gt; 1)); sum[rt \u0026lt;\u0026lt; 1 | 1] += add[rt] * (m \u0026gt;\u0026gt; 1); // 传递后清空增量数组的父节点  add[rt] = 0; } } 在 Push Down 操作中，我们已经保证了这个更新是最小的可查询的粒度。那么，如果我们在后面要在后面去查询更细的粒度，我们要怎么办呢？其实，思路很简单，当我们查询的时候，也执行 Push Down 按照之前需要更新的范围继续向下更新，是不是就可以了。\n我们来修改一下查询操作的代码，让他支持区间批量修改操作引入后的边查询、边修改的升级版。\nint query(int L, int R, int l, int r, int rt) { if (L \u0026lt;= l \u0026amp;\u0026amp; r \u0026lt;= R) { return sum[rt]; } // 如果查询的时候遇到了增量数组，则向下更新一下  // 因为后续要对下层区间和进行查询，所以需要最新的状态  push_down(rt , r - l + 1); int m = (l + r) \u0026gt;\u0026gt; 1; int ret = 0; if (L \u0026lt;= m) ret += query(L , R , l, m, rt * 2); if (m \u0026lt; R) ret += query(L , R , m + 1, r, rt * 2 + 1); return ret; } 同样的，由于 Update 区间操作也需要想查询一样最小的可更新粒度，所以我们在每查询到一个节点时，也对其增加一个 Push Down 操作，如此可以保证下方节点都是最新的更新态。\nvoid update(int L, int R, int c, int l, int r, int rt) { if (L \u0026lt;= l \u0026amp;\u0026amp; r \u0026lt;= R) { add[rt] += c; sum[rt] += c * (r - l + 1); return; } // 如果 update 更细粒度的节点，我们将其增量向下推一层获得最新状态  push_down(rt, r - l + 1); int m = (l + r) \u0026gt;\u0026gt; 1; if (L \u0026lt;= m) { update(L, R, c, l, m, rt \u0026lt;\u0026lt; 1); } if (m \u0026lt; R) { update(L, R, c, m + 1, r, rt \u0026lt;\u0026lt; 1 | 1); } push_up(rt); } Unit Test #  使用上面图示中的线段树，我们来写一个单元测试。分别对应以下操作：\n 建立区间和线段树； 查询 [1, 1] 节点； 查询 [1, 6] 节点； 更新 [1, 6] 节点，全部增加 4； 查询 [1, 6] 节点； 查询 [1, 2] 节点；  #include \u0026lt;iostream\u0026gt;#include \u0026lt;vector\u0026gt;using namespace std; const int maxn = 100000; vector\u0026lt;int\u0026gt; desc = {0, 1, 8, 3, 4, 7, 1, 6, 2}; int cur = 1; int add[maxn \u0026lt;\u0026lt; 2]; int sum[maxn \u0026lt;\u0026lt; 2]; void push_up(int rt) { sum[rt] = sum[rt \u0026lt;\u0026lt; 1] + sum[rt \u0026lt;\u0026lt; 1 | 1]; } void push_down(int rt, int m) { if (add[rt]) { add[rt \u0026lt;\u0026lt; 1] += add[rt]; add[rt \u0026lt;\u0026lt; 1 | 1] += add[rt]; sum[rt \u0026lt;\u0026lt; 1] += add[rt] * (m - (m \u0026gt;\u0026gt; 1)); sum[rt \u0026lt;\u0026lt; 1 | 1] += add[rt] * (m \u0026gt;\u0026gt; 1); add[rt] = 0; } } void build(int l, int r, int rt) { add[rt] = 0; if (l == r) { cout \u0026lt;\u0026lt; rt \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; desc[cur] \u0026lt;\u0026lt; endl; sum[rt] = desc[cur ++]; return; } int m = (l + r) \u0026gt;\u0026gt; 1; build(l, m, rt * 2); build(m + 1, r, rt * 2 + 1); push_up(rt); } void update(int L, int R, int c, int l, int r, int rt) { if (L \u0026lt;= l \u0026amp;\u0026amp; r \u0026lt;= R) { add[rt] += c; sum[rt] += c * (r - l + 1); return; } push_down(rt, r - l + 1); int m = (l + r) \u0026gt;\u0026gt; 1; if (L \u0026lt;= m) { update(L, R, c, l, m, rt \u0026lt;\u0026lt; 1); } if (m \u0026lt; R) { update(L, R, c, m + 1, r, rt \u0026lt;\u0026lt; 1 | 1); } push_up(rt); } int query(int L, int R, int l, int r, int rt) { if (L \u0026lt;= l \u0026amp;\u0026amp; r \u0026lt;= R) { return sum[rt]; } push_down(rt , r - l + 1); int m = (l + r) \u0026gt;\u0026gt; 1; int ret = 0; if (L \u0026lt;= m) ret += query(L , R , l, m, rt * 2); if (m \u0026lt; R) ret += query(L , R , m + 1, r, rt * 2 + 1); return ret; } int main() { build(1, 8, 1); // [1, 8, 3, 4, 7, 1, 6, 2]  cout \u0026lt;\u0026lt; query(1, 1, 1, 8, 1) \u0026lt;\u0026lt; endl; // 1  cout \u0026lt;\u0026lt; query(1, 6, 1, 8, 1) \u0026lt;\u0026lt; endl; // 1 + 8 + 3 + 4 + 7 + 1= 24  update(1, 6, 4, 1, 8, 1); // [5, 12, 7, 8, 11, 5, 6, 2]  cout \u0026lt;\u0026lt; query(1, 6, 1, 8, 1) \u0026lt;\u0026lt; endl; // 5 + 12 + 7 + 8 + 11 + 5 = 48  cout \u0026lt;\u0026lt; query(1, 2, 1, 8, 1) \u0026lt;\u0026lt; endl; // 5 + 12 = 17  return 0; } 也许在读完之后，你会觉得这是一种很巧妙的区间增减操作，因为它是面向查询的。是的，这就是算法中的“惰性”（Lazy）思想，我们前面在并查集中也见到了这种优化。\n"});index.add({'id':19,'href':'/algo/docs/part3/ch02/2-segment-tree-combat/','title':"线段树实战要点",'section':"Docs",'content':"在上一公众号中 《用线段树再看 RMQ 问题》，通过区间和的问题场景，已经学习了线段树的基本结构，以及其单点更新和区间查询的操作。但是在解 《LeetCode-307 区域和检索 - 数组可修改》 这道题目的时候，并不是一帆风顺的。所以这一篇文章我们来讨论一下线段树在做题时会遇到的一些坑。\n空间退化问题 #  在 《LeetCode-307 区域和检索 - 数组可修改》 中，我们会遇到下标索引超出范围的 9/10 的 case。这也就是我们遇到的第一个最直观的坑。\n上文我们说过，线段树是一棵 完美二叉树(Perfect Binary Tree)，可是题目中给出的结点个数不一定是   \\(2^N\\)  次幂个。所以，这就带来了 空间结构退化的问题。\n这里我们假设 N = 13 这个情况，然后我们通过之前的线段树代码进行代码实现后其结构变成了这样：\n通过上图，我们发现如果我们使用 2N = 26 的数组空间，实际上线段树已经覆盖了下标 31 ，这个场景下我们开 2N 的数组是不够的。\n这里直接说结论：我们对线段树的描述数组开 4N 的空间，是绝对够用的。 具体的证明后续文章中单独写。\n在谈 RMQ 问题 #  在第一篇文章中，我们讲了区间和的场景，将最重要的向上更新操作 Push Up 也做了介绍，并且给大家留了一道思考题：如何使用线段树来实现 RMQ 问题。\n其实我们只需要修改两个地方：\n 在向上更新的时候，重新制定规则 - 父结点是两个子节点的大值； 在查询的时候，将结果取递归搜索的大值；  代码如下：\n// 吸取上面的教训，现在我们数组开 4 倍 int tree[maxn \u0026lt;\u0026lt; 2]; void push_up(int rt) { // 父结点是子节点中的最大值  tree[rt] = max(tree[rt \u0026lt;\u0026lt; 1], tree[rt \u0026lt;\u0026lt; 1 | 1]); } int query(int L, int R, int l, int r, int rt) { if (L \u0026lt;= l \u0026amp;\u0026amp; r \u0026lt;= R) { return tree[rt]; } int m = (l + r) \u0026gt;\u0026gt; 1; int ret = 0; // 修改成递归查找区间最大值当做查询结果  if (L \u0026lt;= m) ret = max(ret, query(L, R, l, m, rt \u0026lt;\u0026lt; 1)); if (R \u0026gt; m) ret = max(ret, query(L, R, m + 1, r, rt \u0026lt;\u0026lt; 1 | 1)); return ret; } 其实 RMQ 线段树并没有对线段树结构有任何改变，仅仅是修改了父子结点间的运算规则。\n这样我们对于线段树的理解又加深了一层，因为“线段”并不仅仅代表着一段的加和，延伸来看，其实对某一块区间有着一定结果的运算规则，就可以使用线段树结构来优化查询和更新效率。\n求解逆序数 #  这是一个很典型的统计场景，具体的题目是 《LeetCode-493 翻转对》 ，其实就是在大学时《线性代数》课程中的求逆序数。由于在课程题目中，每个数都是有规律的，所以我们根据通项公式或者递推公式就可以求解。但是这道题目是给我们一个任意的数组，不存在数列所具有的特殊性，所以我们只能通过统计的效率来解决这个问题。\n 逆序数的简单介绍：假设我们有这样一组数 [2, 4, 3, 5, 1]，它有 5 个逆序对，分别是 (2, 1)、(4, 3)、(4, 1)、(3, 1)、(5, 1)，我们要求的答案是，以每个数为首位逆序数的个数，例如上述这组需要输出 [1, 2, 1, 1, 0]。\n 这种题我们应该如何考虑呢？我们换一个角度考虑，假设我们有一个以正整数范围的空线段树，仍旧是区间和线段树，这棵树的每一个叶子结点记录的是当前下标数字出现的次数。\n我们需要的操作仍旧是 单点更新 和 区间查询。顺着以下思路来考虑问题：\n 构建一个 [1, MAXN] 范围的线段树，所有结点全部填 0。MAXN 代表数组中数字的最大值； 反向遍历传入的数组； 遍历到 x 的时候，对线段树做一次 query(1, x - 1) 操作，来记录有多少个比 x 小的数已经出现； 对线段树执行一次 update(x, num + 1) 操作，让线段树更新 x 的计数，做加 1 操作； 重复 3-4 操作，每次的 query 结果就是最后数组中对应的每一个值。  您的浏览器不支持 video 标签。  如上面的动画所示，Nums 的箭头代表遍历情况，Result 数组代表最终的返回结果，右边的操作记录是对线段树的操作 Log。\n离散化 #  在上面求解逆序对的题目中，其求解的情况是不完整的。因为我们将数组中的数字全部映射到了数组的下标中，但是数组中的每个数字的取值范围是  \\([-2^{31}, 2^{31}]\\)  ，如果出现负数和零那就无法完成映射了（因为线段树的下标都是正数）。在这种情况下我们要如何解决这个问题呢？\n这里给出这两点思考方向：\n 虽然每个数字的取值范围是  \\([-2^{31}, 2^{31}]\\)  ，但是给定数组的长度不会超过 50000； 逆序对只是比较了两个数的大小关系，而不用在意具体的数字是多少；  这两点是不是可以理解成，如果我们将这 N 个数，根据大小关系，映射到 [1, 50000] 这个范围内就可以解决问题了？\n例如我们有这么一组数 [-1, -5, 0, 12, 8]，我们先升序排序处理一下 [-5, -1, 0, 8, 12] ，然后做一个 Hash 来映射到整数范围 {-5: 1, -1: 2, 0: 3, 8: 4, 12: 5}。通过 Hash 我们的数组变成了 [2, 1, 3, 5, 4] 。如此我们就可以继续使用上面的思路来求解了。\n是不是这个思路非常巧妙~ 其实这种区间问题只涉及到大小关系的时候，都可以通过这个方法进行数字映射，从而投影到我们可求解的区域内。这种思路就叫做离散化。所谓的离散化官方的定义就是：把无限空间中有限的个体映射到有限的空间中去，以此提高算法的时空效率。当我们对这类题目求解的时候，由于我们缩小了求解范围，从而算法的时间常数和空间复杂度都会有所降低，所以离散化也是最容易想到的优化点之一。\n希望大家学习了逆序场景以及离散化的优化思路，可以自行 AC 这道题。另外，《LeetCode-493 翻转对》 这个题目也可以通过这两个思路来尝试解决一下。\n优美的 notonlysuccess 写法 #  notonlysuccess 是一个 ACM-ICPC 的前辈（网络号 id），因为他的线段树代码十分清晰且优雅，所以他的代码经常作为各个参赛选手的模板代码（虽然线段树最后大家都能徒手写出来）。具体何为优雅，下面放上 notonlysuccess 的线段数区间和的代码（其实在我公众号上，所有的代码风格都是在模仿 notonlysuccess，Respect ！！）：\n#include \u0026lt;cstdio\u0026gt; // 优雅点 1：参数宏定义 #define lson l , m , rt \u0026lt;\u0026lt; 1 #define rson m + 1 , r , rt \u0026lt;\u0026lt; 1 | 1  const int maxn = 55555; int sum[maxn \u0026lt;\u0026lt; 2]; // 优雅点 2：PushUp 抽离 void PushUP(int rt) { sum[rt] = sum[rt \u0026lt;\u0026lt; 1] + sum[rt \u0026lt;\u0026lt; 1 | 1]; } void build(int l, int r, int rt) { if (l == r) { scanf(\u0026#34;%d\u0026#34;, \u0026amp;sum[rt]); return ; } // 优雅点 3：能用位运算就用位运算  int m = (l + r) \u0026gt;\u0026gt; 1; build(lson); build(rson); PushUP(rt); } void update(int p, int add, int l, int r, int rt) { if (l == r) { sum[rt] += add; return ; } int m = (l + r) \u0026gt;\u0026gt; 1; if (p \u0026lt;= m) update(p , add , lson); else update(p , add , rson); PushUP(rt); } int query(int L, int R, int l, int r, int rt) { if (L \u0026lt;= l \u0026amp;\u0026amp; r \u0026lt;= R) { return sum[rt]; } int m = (l + r) \u0026gt;\u0026gt; 1; int ret = 0; if (L \u0026lt;= m) ret += query(L , R , lson); if (R \u0026gt; m) ret += query(L , R , rson); return ret; } 总结 #  这篇文章讲述了在题目实战中使用线段树的一些技巧。包括：\n 数组上限大小； RMQ 线段树实现方式； 逆序数使用线段树的求解思路； 离散化的优化方法； notonlysuccess 版优雅线段树模板；   附录：关于线段树开 4N 空间的证明 #  先给出一条待证明的定理：当  \\(n \\geq 3\\)  ，一个  \\([1, n]\\)  的线段树可以将 \\([1, n]\\)  的任意区间 \\([L, R]\\)  分解成不超过  \\(2\\lfloor log_2{(n-1)} \\rfloor \\)  个子区间。\n证明 #  用数学归纳法，证明上面的定理：\n首先, \\(n=3,4,5\\)  时，用穷举法不难证明定理成立。\n假设对于 \\(n= 3,4,5,...,k-1\\)  上式都成立，下面来证明对于 \\(n=k (k\\geq 6)\\)  成立：\n分为 4 种情况来证明：\n 情况一   \\([L, R]\\)  包含根节点 \\((L=1, R=n)\\)  ，此时， \\([L, R]\\)  被分解成为了一个节点，定理成立。\n 情况二   \\([L, R]\\)  包含根节点的左子节点，此时 \\([L, R]\\)  一定不包含根的右子节点（因为如果包含，就可以合并左右子节点，用根节点替代，此时就是情况一）。这时，以右节点为根的这个树的元素个数为  \\(\\lfloor \\frac{k}{2} \\rfloor \\geq 3 \\)   \\([L, R] \\)  分成的子区间由两部分组成：\n 根的左子节点，区间数为 1 以根的右子节点为根的树种，进行区间查询，这个可以递归使用本定理。  所以综上，  \\([L, R] \\)  一共被分成了  \\( 1 \u0026#43; 2\\lfloor log_2{(\\lfloor \\frac{k}{2} \\rfloor - 1) \\rfloor} \\)  个区间\n 情况三  同情况二对称，不一样的是，以根的左子节点为根的元素个数为  \\(\\lfloor \\frac{k \u0026#43; 1}{2} \\rfloor \\geq 3 \\)  。\n \\([L, R] \\)  一共被划分成了  \\( 1 \u0026#43; 2\\lfloor log_2{(\\lfloor \\frac{k}{2} \\rfloor - 1) \\rfloor} \\)  个区间。\n从公式可以看出，情况二的区间小于等于情况三的区间数，于是只需要证明情况三的区间数符合条件就行。\n \\[\\begin{aligned} \u0026amp; 1 \u0026#43; 2\\lfloor log_2{(\\lfloor \\frac{k \u0026#43; 1}{2} \\rfloor - 1) \\rfloor} \\\\ = \u0026amp; 1 \u0026#43; 2\\lfloor log_2{(\\lfloor \\frac{k \u0026#43; 1}{2} \\rfloor) \\rfloor} \\\\ \\leq \u0026amp; 1 \u0026#43; 2\\lfloor log_2{(\\frac{k \u0026#43; 1}{2}) \\rfloor} \\\\ = \u0026amp; 1 \u0026#43; 2\\lfloor log_2{(k-1)-1} \\rfloor \\\\ = \u0026amp; 2\\lfloor log_2{(k-1)} \\rfloor - 1 \\\\ \u0026lt; \u0026amp; 2\\lfloor log_2{(k-1)} \\rfloor \\end{aligned}\\]  所以，情况二和情况三定理成立。\n 情况四   \\([L, R]\\)  不包括根节点以及根节点的左右子节点。\n于是，剩下的  \\(2\\lfloor log_2{(k-1)} \\rfloor\\)  层，每层最多两个节点。\n所以， \\([L, R]\\)  最多被分解成了  \\(2\\lfloor log_2{(k-1)} \\rfloor\\)  个区间，定理成立。\n 综上  综上，当  \\(n \\geq 3\\)  ，一个  \\([1, n]\\)  的线段树可以将 \\([1, n]\\)  的任意区间 \\([L, R]\\)  分解成不超过  \\(2\\lfloor log_2{(n-1)} \\rfloor \\)  个子区间。\n证毕。\n但需要注意的是， \\(2\\lfloor log_2{(n-1)} \\rfloor \\)  是上界，但不是最小上界。所以我们来测试一下  \\(4n \\geq 2\\lfloor log_2{(n-1)} \\rfloor\\)  是否成立？\n \\[\\begin{aligned} 4n \u0026amp; \\geq 2\\lfloor log_2{(n-1)} \\\\ 2n \u0026amp; \\geq log_2{(n-1)} \\\\ 4^{n} \u0026amp; \\geq n - 1 \\end{aligned}\\]  所以我们发现，当  \\(n\\)  取自然数  \\(1, 2, 3, ...\\)  均成立。\n"});})();